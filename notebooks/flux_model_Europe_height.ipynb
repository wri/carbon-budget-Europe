{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68a34f07-629a-4998-a946-fe7cad4fd82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'   # Suppresses some warning about geopandas\n",
    "import geopandas as gpd\n",
    "\n",
    "# scipy basics\n",
    "import numpy as np\n",
    "import botocore\n",
    "from osgeo import gdal      # Necessary to do this import to get rasterio to import\n",
    "import rasterio as rio\n",
    "import rasterio.features\n",
    "\n",
    "import time\n",
    "\n",
    "# dask/parallelization libraries\n",
    "import coiled\n",
    "import dask\n",
    "import dask.array as dar\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "import xrspatial.local\n",
    "\n",
    "# Suppresses the BokehUserWarnings\n",
    "# https://discourse.bokeh.org/t/how-to-silence-bokeh-warnings/2491/7\n",
    "from bokeh.util.warnings import BokehUserWarning, warnings \n",
    "warnings.simplefilter(action='ignore', category=BokehUserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee816d-ec30-407d-9e90-2ec19abb7570",
   "metadata": {},
   "source": [
    "<font size=\"6\">Making cloud and local clusters</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa049d7-038a-4315-8d18-460189e64463",
   "metadata": {},
   "outputs": [],
   "source": [
    "coiled_cluster = coiled.Cluster(\n",
    "    n_workers=10,\n",
    "    use_best_zone=True, \n",
    "    compute_purchase_option=\"spot_with_fallback\",\n",
    "    idle_timeout=\"20 minutes\",\n",
    "    # name=\"DGibbs Europe height flux model\", \n",
    "    account='jterry64'   # Necessary to use the AWS environment that Justin set up in Coiled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af3add9-2aac-404c-9df9-1d8a5c5fac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coiled cluster (cloud run)\n",
    "coiled_client = coiled_cluster.get_client()\n",
    "coiled_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b141e-5959-4327-b5c3-ea526cfe35c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Local cluster (local run). Doesn't work-- .compute() method kill workers for unknown reasons. Can't use for now.\n",
    "# # local_cluster = LocalCluster(silence_logs=False)\n",
    "# local_cluster = LocalCluster()\n",
    "# local_client = Client(local_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8239a-b9d1-4a92-9288-b1c6a0f715ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local single-process cluster (local run). Will run .compute() on just one process, not a whole cluster.\n",
    "local_client = Client(processes=False)\n",
    "local_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3254c347-db70-4f46-81ed-f465d088ffbf",
   "metadata": {},
   "source": [
    "<font size=\"6\">Shutting down cloud and local clusters</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67184a6f-e7e1-4533-976e-3bcdbd9ffc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "coiled_cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30ed24d-64f6-4b47-aa0d-e762e941301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2d5b5e-1324-433c-b7fa-749df243954c",
   "metadata": {},
   "source": [
    "<font size=\"6\">Analysis</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3e94c-e033-46d5-8b88-7da2cc98ce5b",
   "metadata": {},
   "source": [
    "<font size=\"4\">General paths and functions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee7c485-ae2e-4f66-b065-1d7f5d3a0dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General paths and constants\n",
    "\n",
    "general_uri = 's3://gfw2-data/forest_change/GLAD_Europe_height_data/'\n",
    "\n",
    "local_out_dir = 'C:\\\\GIS\\\\Carbon_model_Europe\\\\outputs\\\\'\n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d\")\n",
    "\n",
    "tile_size = 10      # Tile size is from the top left of the tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d865a013-57ec-42ad-acd9-3844d53e303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads tile\n",
    "# From https://notebooks-staging.wri.org/user/dagibbs22/lab/tree/msims/biodiversity_global_stats.ipynb\n",
    "# Bounding box use comes from https://github.com/corteva/rioxarray/issues/115#issuecomment-1206673437 and https://corteva.github.io/rioxarray/html/examples/clip_box.html. \n",
    "\n",
    "# Tile size is from the top left of the tile\n",
    "def get_tile_dataset(uri, name, template=None, tile_size=10):\n",
    "    # If the input tile_size is too large, it reverts to 10 (standard tile size)\n",
    "    if tile_size > 10:\n",
    "        tile_size = 10\n",
    "    try:\n",
    "        raster = rioxarray.open_rasterio(uri, chunks=1000, default_name=name)\n",
    "        raster_extent = raster.rio.bounds()\n",
    "        minx=raster_extent[0]\n",
    "        miny=raster_extent[1]\n",
    "        maxx=raster_extent[2]\n",
    "        maxy=raster_extent[3]\n",
    "        return raster.rio.clip_box(minx=minx, miny=maxy-tile_size, maxx=minx+tile_size, maxy=maxy)\n",
    "        # return raster.rio.clip_box(minx=10, miny=45, maxx=15, maxy=50)       # 5x5 deg\n",
    "        # return raster.rio.clip_box(minx=10, miny=48, maxx=12, maxy=50)       # 2x2 deg\n",
    "        # return raster.rio.clip_box(minx=10, miny=49, maxx=11, maxy=50)       # 1x1 deg\n",
    "    except rasterio.errors.RasterioIOError as e:\n",
    "        if template is not None:\n",
    "            return xr.zeros_like(template)\n",
    "        else:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfd36e2-7878-475e-b95f-cf6ecaf3463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_dims(forest_height_previous, forest_height_current, forest_loss_detection, driver, planted_forest_type, peat, tclf):\n",
    "#\n",
    "    forest_height_previous_max = forest_height_previous.max().compute().values.item(0)+1\n",
    "    forest_height_current_max = forest_height_current.max().compute().values.item(0)+1\n",
    "    forest_loss_detection_max = forest_loss_detection.max().compute().values.item(0)+1\n",
    "    driver_max = driver.max().compute().values.item(0)+1\n",
    "    planted_forest_type_max = planted_forest_type.max().compute().values.item(0)+1\n",
    "    peat_max = peat.max().compute().values.item(0)+1\n",
    "    tclf_max = tclf.max().compute().values.item(0)+1\n",
    "\n",
    "    return (forest_height_previous_max, forest_height_current_max, forest_loss_detection_max, driver_max, planted_forest_type_max, peat_max, tclf_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c493b4b-096c-4650-9e30-0202bc5dd59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines the values from all the inputs into a one-dimensional index of unique values for every combination of input layer pixel values\n",
    "\n",
    "# # Maximum value for each input layer in the order in which they will be stacked (so, must match order in consolidate_to_one_dimensional_index)\n",
    "# index_dims = (40, 40, 2, 6, 5, 2, 25)\n",
    "\n",
    "# Turns the multidimensional array into a 1-D array in which each combination of input values results in a unique index\n",
    "def consolidate_to_one_dimensional_index(chunk):\n",
    "    return xr.DataArray(np.ravel_multi_index(\n",
    "            [chunk.forest_height_previous.data, \n",
    "             chunk.forest_height_current.data,\n",
    "             chunk.forest_loss_detection.data,\n",
    "             chunk.driver.data,\n",
    "             chunk.planted_forest_type.data,\n",
    "             chunk.peat.data,\n",
    "             chunk.tclf.data\n",
    "            ], \n",
    "        index_dims(forest_height_previous, forest_height_current, forest_loss_detection, driver, planted_forest_type, peat, tclf)), \n",
    "    coords=chunk.coords, dims=chunk.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea2076-8177-4fba-9ded-7201ba4d21ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines the values from all the inputs into a one-dimensional index of unique values for every combination of input layer pixel values\n",
    "\n",
    "# Maximum value for each input layer in the order in which they will be stacked (so, must match order in consolidate_to_one_dimensional_index)\n",
    "index_dims = (40, 40, 2, 6, 5, 2, 25)\n",
    "\n",
    "# Turns the multidimensional array into a 1-D array in which each combination of input values results in a unique index\n",
    "def consolidate_to_one_dimensional_index(chunk):\n",
    "    return xr.DataArray(np.ravel_multi_index(\n",
    "            [chunk.forest_height_previous.data, \n",
    "             chunk.forest_height_current.data,\n",
    "             chunk.forest_loss_detection.data,\n",
    "             chunk.driver.data,\n",
    "             chunk.planted_forest_type.data,\n",
    "             chunk.peat.data,\n",
    "             chunk.tclf.data\n",
    "            ], \n",
    "        index_dims), coords=chunk.coords, dims=chunk.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e270a478-9046-4f07-a917-44dcf3d8723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a class that encapsulates all the pixel data passed into the decision tree for classification. \n",
    "# This makes it much easier to read how the decision tree uses the pixel data. \n",
    "# Also a place to do any modifications to the input data or add additional fields based off of the input data.\n",
    "\n",
    "class ForestStateDecisionFactors:\n",
    "    def __init__(self, height_prev_year, height_this_year, forest_loss_detection, driver, planted_forest_type, peat, tclf):\n",
    "        self.height_prev_year = height_prev_year\n",
    "        self.height_this_year = height_this_year\n",
    "        self.forest_loss_detection = forest_loss_detection\n",
    "        self.driver = driver \n",
    "        self.planted_forest_type = planted_forest_type\n",
    "        self.peat = peat\n",
    "        self.tclf = tclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c10b5d6-ef4c-4172-bceb-fc13eba26f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree for assigning forest classes. \n",
    "# Takes the above decision factors class, which includes all the data in input layers at one pixel, and classifes it using the decision tree logic.\n",
    "\n",
    "class ForestStateDecisionTree:\n",
    "    # define in a way similar to how we went over with Gary\n",
    "    def classify(forestStateDecisionFactors):\n",
    "        if forestStateDecisionFactors.height_prev_year >= 5 and forestStateDecisionFactors.height_this_year >= 5:   # maintained\n",
    "            return 1\n",
    "        elif forestStateDecisionFactors.height_prev_year >= 5 and forestStateDecisionFactors.height_this_year < 5:  # loss\n",
    "            return 2\n",
    "        elif forestStateDecisionFactors.height_prev_year < 5 and forestStateDecisionFactors.height_this_year >= 5:  # gain\n",
    "            return 3\n",
    "        else:                                                                                                       # no forest\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb4cc0e-fc6f-43fb-9282-cf2c40b66e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree for assigning forest classes. \n",
    "# Takes the above decision factors class, which includes all the data in input layers at one pixel, and classifes it using the decision tree logic.\n",
    "\n",
    "class ForestStateDecisionTree:\n",
    "    # define in a way similar to how we went over with Gary\n",
    "    def classify(forestStateDecisionFactors):\n",
    "        if forestStateDecisionFactors.height_prev_year >= 5 and forestStateDecisionFactors.height_this_year >= 5:   # maintained\n",
    "            return 1\n",
    "        elif forestStateDecisionFactors.height_prev_year < 5 and forestStateDecisionFactors.height_this_year >= 5:  # gain\n",
    "            return 2\n",
    "        elif ((forestStateDecisionFactors.height_prev_year >= 5 and forestStateDecisionFactors.height_this_year < 5) or (forest_loss_detection == 1)).all():  # loss\n",
    "            if forestStateDecisionFactors.planted_forest_type > 0:\n",
    "                if forestStateDecisionFactors.peat == 1:\n",
    "                    return 311\n",
    "                else:\n",
    "                    return 31\n",
    "            else:\n",
    "                return 3\n",
    "        else:                                                                                                       # no forest\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a99c55-7c9f-4ab5-9e7a-278ce20cb0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts 1-D array of unique indexes back to your layer values and classifies them to a forest state\n",
    "# three versions\n",
    "\n",
    "def classify_index(index):\n",
    "    decisionFactors = ForestStateDecisionFactors(*np.unravel_index(index, index_dims))\n",
    "    return ForestStateDecisionTree.classify(decisionFactors)\n",
    "\n",
    "\n",
    "# @dask.delayed\n",
    "# def classify_index(index):\n",
    "#     decisionFactors = ForestStateDecisionFactors(*np.unravel_index(index, index_dims))\n",
    "#     return ForestStateDecisionTree.classify(decisionFactors)\n",
    "\n",
    "\n",
    "# # Does not work because ndarray does not accept .apply(). This was suggested by Justin\n",
    "# def classify_index(index):\n",
    "#     decisionFactors = ForestStateDecisionFactors(*np.unravel_index(index, index_dims))\n",
    "#     return ForestStateDecisionTree.classify(decisionFactors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d280f7-fdfe-4b5f-93be-3ad4b7c736ef",
   "metadata": {},
   "source": [
    "<font size=\"4\">Running without for loop</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b98ef62-e818-4bbd-be89-59e729f75feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file locations\n",
    "# forest_height_previous_uri = f'{general_uri}202307_revision/FH_2020.tif'\n",
    "# forest_height_current_uri = f'{general_uri}202307_revision/FH_2021.tif'\n",
    "# forest_loss_detection_uri = f'{general_uri}202307_revision/DFL_2021.tif'\n",
    "\n",
    "# forest_height_previous_uri = f'{general_uri}202307_revision/test_1x1_deg/50N_010E_1deg_FH_2020.tif'\n",
    "# forest_height_current_uri = f'{general_uri}202307_revision/test_1x1_deg/50N_010E_1deg_FH_2021.tif'\n",
    "# forest_loss_detection_uri = f'{general_uri}202307_revision/test_1x1_deg/50N_010E_1deg_DFL_2020.tif'\n",
    "\n",
    "forest_height_previous_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_FH_2020.tif'\n",
    "forest_height_current_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_FH_2021.tif'\n",
    "forest_loss_detection_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_DFL_2020.tif'\n",
    "\n",
    "driver_uri = \"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/tree_cover_loss_drivers/processed/drivers_2022/20230407/50N_010E_tree_cover_loss_driver_processed.tif\"\n",
    "planted_forest_type_uri = \"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/planted_forest_type/SDPT_v1/standard/20200730/50N_010E_plantation_type_oilpalm_woodfiber_other_unmasked.tif\"\n",
    "peat_uri = \"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/peatlands/processed/20230315/50N_010E_peat_mask_processed.tif\"\n",
    "tclf_uri = \"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/tree_cover_loss_fires/20230315/processed/50N_010E_tree_cover_loss_fire_processed.tif\"\n",
    "\n",
    "# land_cover_uri = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff9797-8b18-4a4b-8c51-f813a4fe3a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads input files\n",
    "forest_height_previous = get_tile_dataset(forest_height_previous_uri, name=\"forest_height_previous\", tile_size=tile_size)\n",
    "forest_height_current = get_tile_dataset(forest_height_current_uri, name=\"forest_height_current\", tile_size=tile_size)\n",
    "forest_loss_detection = get_tile_dataset(forest_loss_detection_uri, name=\"forest_loss_detection\", tile_size=tile_size)\n",
    "\n",
    "driver = get_tile_dataset(driver_uri, name=\"driver\", tile_size=tile_size)\n",
    "planted_forest_type = get_tile_dataset(planted_forest_type_uri, name=\"planted_forest_type\", tile_size=tile_size)\n",
    "peat = get_tile_dataset(peat_uri, name=\"peat\", tile_size=tile_size)\n",
    "tclf = get_tile_dataset(tclf_uri, name=\"tclf\", tile_size=tile_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e86512e-c421-4ca1-bbaf-d01646f29e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Some sample dask operations\n",
    "\n",
    "print(forest_height_previous.mean().compute().values.item(0))\n",
    "print(forest_height_current.mean().compute().values.item(0))\n",
    "# print(forest_loss_detection.mean().compute().values.item(0))\n",
    "# print(driver.mean().compute().values.item(0))\n",
    "# print(planted_forest_type.mean().compute().values.item(0))\n",
    "# print(peat.mean().compute().values.item(0))\n",
    "# print(tclf.mean().compute().values.item(0))\n",
    "forest_height_previous\n",
    "# print(forest_height_previous.where(driver > 1).mean().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd7a3de-38fe-426d-b633-24f850147ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines all inputs into one xarray dataset, \n",
    "# which is just a way to group arrays that are aligned on the same coordinates\n",
    "\n",
    "decision_tree_ds = xr.Dataset({\n",
    "    \"forest_height_previous\": forest_height_previous, \n",
    "    \"forest_height_current\": forest_height_current,\n",
    "    \"forest_loss_detection\": forest_loss_detection,\n",
    "    \"driver\": driver,\n",
    "    \"planted_forest_type\": planted_forest_type,\n",
    "    \"peat\": peat,\n",
    "    \"tclf\": tclf\n",
    "})\n",
    "\n",
    "decision_tree_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ececb39-7e2b-476f-992a-a873931d7b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Uses the function above to map the dataset to 1D index\n",
    "\n",
    "decision_tree_index = decision_tree_ds.map_blocks(consolidate_to_one_dimensional_index, template=forest_height_previous.copy())\n",
    "decision_tree_index.compute()\n",
    "# decision_tree_index.mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40553cef-d17e-4a2e-b86e-e1f3b48f9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the decision tree index array to raster\n",
    "\n",
    "decision_tree_index.rio.to_raster(f'{local_out_dir}decision_tree_index_2021__{timestr}_not_for_loop.tif', compress='DEFLATE', dtype='uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f171324-be3c-461a-84cf-35c6d7a53c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Finds all unique index values across the tile\n",
    "\n",
    "unique_indices = dar.unique(decision_tree_index.data)\n",
    "unique_indices.compute_chunk_sizes()   #Added to resolve unknown chunk size error: https://docs.dask.org/en/latest/array-chunks.html#unknown-chunks\n",
    "unique_indices = unique_indices.compute()\n",
    "# print(unique_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a586f8f5-e9f7-4b79-a594-28ffc4ec1cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Converts the array of unique index values back to forest states\n",
    "\n",
    "forest_states_per_index = [classify_index(index) for index in unique_indices]\n",
    "# forest_states_per_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b72f9de-02cf-473e-af6e-9a8ba2b977c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Swaps the unique indices for their corresponding forest states\n",
    "\n",
    "forest_states = xrspatial.classify.reclassify(\n",
    "    decision_tree_index.squeeze(\"band\"),\n",
    "    bins=unique_indices, \n",
    "    new_values=forest_states_per_index,\n",
    "    name=\"forest_states\"\n",
    ")\n",
    "forest_states_final = forest_states.compute()\n",
    "print(forest_states_final)\n",
    "print(forest_states_final.mean().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f62eb-3ccd-4c02-b809-49f6898456de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the forest state raster\n",
    "\n",
    "forest_states_final.rio.to_raster(f'{local_out_dir}forest_states_2021__{timestr}_{tile_size}_deg__not_for_loop.tif', compress='DEFLATE', dtype='uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7875fb-1d3f-414f-8ca2-9e739271d203",
   "metadata": {},
   "source": [
    "<font size=\"4\">Running with for loop</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c8138d-2045-46d6-96c2-574bb97928c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tile_id_list = [\"50N_010E\"]\n",
    "\n",
    "tile_size = 1\n",
    "\n",
    "# years = [2019, 2020, 2021]\n",
    "years = [2021]\n",
    "\n",
    "for tile_id in tile_id_list:\n",
    "\n",
    "    driver_uri = \"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/tree_cover_loss_drivers/processed/drivers_2022/20230407/50N_010E_tree_cover_loss_driver_processed.tif\"\n",
    "    planted_forest_type_uri = \"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/planted_forest_type/SDPT_v1/standard/20200730/50N_010E_plantation_type_oilpalm_woodfiber_other_unmasked.tif\"\n",
    "    peat_uri = \"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/peatlands/processed/20230315/50N_010E_peat_mask_processed.tif\"\n",
    "    tclf_uri = \"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/tree_cover_loss_fires/20230315/processed/50N_010E_tree_cover_loss_fire_processed.tif\"\n",
    "\n",
    "    driver = get_tile_dataset(driver_uri, name=\"driver\", tile_size)\n",
    "    planted_forest_type = get_tile_dataset(planted_forest_type_uri, name=\"planted_forest_type\", tile_size)\n",
    "    peat = get_tile_dataset(peat_uri, name=\"peat\", tile_size)\n",
    "    tclf = get_tile_dataset(tclf_uri, name=\"tclf\", tile_size)\n",
    "\n",
    "    for year in years:\n",
    "        \n",
    "        start = time.time()\n",
    "              \n",
    "        current_year = year\n",
    "        previous_year = current_year - 1\n",
    "        print(\"Previous year: \" + str(previous_year))\n",
    "        print(\"Current year: \"+ str(current_year))\n",
    "\n",
    "        # forest_height_previous_uri = f'{general_uri}202307_revision/FH_{previous_year}.tif'\n",
    "        # forest_height_current_uri = f'{general_uri}202307_revision/FH_{current_year}.tif'\n",
    "        # forest_loss_detection_uri = f'{general_uri}202307_revision/DFL_{current_year}.tif'\n",
    "\n",
    "        forest_height_previous_uri = f'{general_uri}202307_revision/test_10x10_deg/{tile_id}_FH_{previous_year}.tif'\n",
    "        forest_height_current_uri = f'{general_uri}202307_revision/test_10x10_deg/{tile_id}_FH_{current_year}.tif'\n",
    "        forest_loss_detection_uri = f'{general_uri}202307_revision/test_10x10_deg/{tile_id}_DFL_{previous_year}.tif'\n",
    "                       \n",
    "        forest_height_previous = get_tile_dataset(forest_height_previous_uri, name=\"forest_height_previous\", tile_size)\n",
    "        forest_height_current = get_tile_dataset(forest_height_current_uri, name=\"forest_height_current_year\", tile_size)\n",
    "        forest_loss_detection_previous = get_tile_dataset(forest_loss_detection_uri, name=\"forest_height_current_year\", tile_size)\n",
    "        \n",
    "        print(\"Previous height mean =\", forest_height_previous.mean().compute().values.item(0))\n",
    "        print(\"Current height mean =\",forest_height_current.mean().compute().values.item(0))\n",
    "        # print(forest_loss_detection.mean().compute().values.item(0))\n",
    "        # print(driver.mean().compute().values.item(0))\n",
    "        # print(planted_forest_type.mean().compute().values.item(0))\n",
    "        # print(peat.mean().compute().values.item(0))\n",
    "        # print(tclf.mean().compute().values.item(0))\n",
    "\n",
    "          \n",
    "        # you'll want to combine them all into one xarray dataset, which is just a way to group arrays that\n",
    "        # are aligned on the same coordinates\n",
    "        decision_tree_ds = xr.Dataset({\n",
    "            \"forest_height_previous\": forest_height_previous, \n",
    "            \"forest_height_current\": forest_height_current,\n",
    "            \"forest_loss_detection\": forest_loss_detection,\n",
    "            \"driver\": driver,\n",
    "            \"planted_forest_type\": planted_forest_type,\n",
    "            \"peat\": peat,\n",
    "            \"tclf\": tclf\n",
    "        })\n",
    "        \n",
    "        # use the function above to map your dataset to that 1D index\n",
    "        print(\"Making index matrix...\")\n",
    "        decision_tree_index = decision_tree_ds.map_blocks(consolidate_to_one_dimensional_index, template=forest_height_previous.copy())\n",
    "        \n",
    "        # # Save the decision tree index array to raster\n",
    "        decision_tree_index_matrix = decision_tree_index.compute()\n",
    "        # print(\"decision_tree_index\")\n",
    "        print(decision_tree_index_matrix)\n",
    "        # decision_tree_index_matrix.rio.to_raster(f'{local_out_dir}{tile_id}_1deg_decision_tree_index_{current_year}__{timestr}.tif', compress='DEFLATE', dtype='uint16')\n",
    "\n",
    "        # find all unique index values across the tile\n",
    "        print(\"Finding unique indices...\")\n",
    "        unique_indices = dar.unique(decision_tree_index.data)\n",
    "        unique_indices.compute_chunk_sizes()   #Added to resolve unknown chunk size error: https://docs.dask.org/en/latest/array-chunks.html#unknown-chunks\n",
    "        unique_indices=unique_indices.compute()\n",
    "        # print(\"Unique indices:\")\n",
    "        # print(unique_indices)\n",
    "        \n",
    "        print(\"Converting unique index list to forest state list...\")\n",
    "        forest_states_per_index = [classify_index(index) for index in unique_indices]\n",
    "\n",
    "        # print(\"forest_states_per_index\")\n",
    "        # print(forest_states_per_index)\n",
    "\n",
    "        print(\"Creating forest state matrix...\")\n",
    "        forest_states = xrspatial.classify.reclassify(\n",
    "            decision_tree_index.squeeze(\"band\"),\n",
    "            bins=unique_indices, \n",
    "            new_values=forest_states_per_index,\n",
    "            name=\"forest_states\"\n",
    "        )\n",
    "        forest_states_final = forest_states.compute()\n",
    "        forest_states_final\n",
    "\n",
    "        print(\"Saving forest state raster...\")\n",
    "        forest_states_final.rio.to_raster(f'{local_out_dir}{tile_id}_5deg_FH_forest_states_{current_year}__{timestr}.tif', compress='DEFLATE', dtype='uint8')\n",
    "        \n",
    "        end = time.time()\n",
    "        print(\"Elapsed time to generate forest states in tile_id {0} for {1} : \".format(tile_id, current_year), round(end-start))\n",
    "\n",
    "#         # # now you can also swap your forest states for emissions/removals factors\n",
    "#         # emissions = (forest_states[forest_states == 1] * (full_biomass + non_co2_peat + non_co2_fire)) + \n",
    "#         #                 (forest_states[forest_states == 2] * partial_biomass + non_co2_peat + non_co2_fire) + ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61703e45-c2c6-4209-9dca-f3b2e52eabef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c73dc-0f36-4f89-8141-e6950426f5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa3ed53-d72e-478f-93ae-b1b8612a2784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc877560-dad4-441f-836b-169e6cdf5701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
