{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a34f07-629a-4998-a946-fe7cad4fd82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'   # Suppresses some warning about geopandas\n",
    "import geopandas as gpd\n",
    "\n",
    "# scipy basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.wkb import loads\n",
    "import botocore\n",
    "from osgeo import gdal      # Necessary to do this import to get rasterio to import\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "\n",
    "import time\n",
    "\n",
    "# dask/parallelization libraries\n",
    "import coiled\n",
    "import dask\n",
    "import dask.array as dar\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask_geopandas\n",
    "import pystac\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "import xrspatial.local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee816d-ec30-407d-9e90-2ec19abb7570",
   "metadata": {},
   "source": [
    "<font size=\"6\">Making cloud and local clusters</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa049d7-038a-4315-8d18-460189e64463",
   "metadata": {},
   "outputs": [],
   "source": [
    "coiled_cluster = coiled.Cluster(\n",
    "    n_workers=20,\n",
    "    use_best_zone=True, \n",
    "    compute_purchase_option=\"spot_with_fallback\",\n",
    "    idle_timeout=\"20 minutes\",\n",
    "    # worker_vm_types=[\"t3.medium\"],\n",
    "    # name=\"DGibbs Europe height flux model\", \n",
    "    account='jterry64'   # Necessary to use the AWS environment that Justin set up in Coiled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af3add9-2aac-404c-9df9-1d8a5c5fac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coiled cluster (cloud run)\n",
    "coiled_client = coiled_cluster.get_client()\n",
    "coiled_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b141e-5959-4327-b5c3-ea526cfe35c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Local cluster (local run). Doesn't work-- .compute() method kill workers for unknown reasons. Can't use for now.\n",
    "# # local_cluster = LocalCluster(silence_logs=False)\n",
    "# local_cluster = LocalCluster()\n",
    "# local_client = Client(local_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8239a-b9d1-4a92-9288-b1c6a0f715ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local single-process cluster (local run). Will run .compute() on just one process, not a whole cluster.\n",
    "local_client = Client(processes=False)\n",
    "local_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3254c347-db70-4f46-81ed-f465d088ffbf",
   "metadata": {},
   "source": [
    "<font size=\"6\">Shutting down cloud and local clusters</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67184a6f-e7e1-4533-976e-3bcdbd9ffc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "coiled_cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30ed24d-64f6-4b47-aa0d-e762e941301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2d5b5e-1324-433c-b7fa-749df243954c",
   "metadata": {},
   "source": [
    "<font size=\"6\">Analysis</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3e94c-e033-46d5-8b88-7da2cc98ce5b",
   "metadata": {},
   "source": [
    "<font size=\"4\">General paths and utilities</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee7c485-ae2e-4f66-b065-1d7f5d3a0dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with and without for loop\n",
    "\n",
    "general_uri = 's3://gfw2-data/forest_change/GLAD_Europe_height_data/'\n",
    "\n",
    "local_out_dir = 'C:\\\\GIS\\\\Carbon_model_Europe\\\\outputs\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d865a013-57ec-42ad-acd9-3844d53e303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with and without for loop\n",
    "# From https://notebooks-staging.wri.org/user/dagibbs22/lab/tree/msims/biodiversity_global_stats.ipynb\n",
    "\n",
    "def get_tile_dataset(uri, name, template=None):\n",
    "    try:\n",
    "        return rioxarray.open_rasterio(uri, chunks=1000, default_name=name)\n",
    "    except rasterio.errors.RasterioIOError as e:\n",
    "        if template is not None:\n",
    "            return xr.zeros_like(template)\n",
    "        else:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e270a478-9046-4f07-a917-44dcf3d8723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with and without for loop\n",
    "\n",
    "class ForestStateDecisionFactors:\n",
    "    def __init__(self, height_prev_year, height_this_year):\n",
    "        self.height_prev_year = height_prev_year\n",
    "        self.height_this_year = height_this_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c10b5d6-ef4c-4172-bceb-fc13eba26f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with and without for loop\n",
    "\n",
    "class ForestStateDecisionTree:\n",
    "    # define in a way similar to how we went over with Gary\n",
    "    def classify(forestStateDecisionFactors):\n",
    "        if forestStateDecisionFactors.height_prev_year >= 5 and forestStateDecisionFactors.height_this_year >= 5:   # maintained\n",
    "            return 1\n",
    "        elif forestStateDecisionFactors.height_prev_year >= 5 and forestStateDecisionFactors.height_this_year < 5:  # loss\n",
    "            return 2\n",
    "        elif forestStateDecisionFactors.height_prev_year < 5 and forestStateDecisionFactors.height_this_year >= 5:  # gain\n",
    "            return 3\n",
    "        else:                                                                                                       # no forest\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d280f7-fdfe-4b5f-93be-3ad4b7c736ef",
   "metadata": {},
   "source": [
    "<font size=\"4\">Running without for loop</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b98ef62-e818-4bbd-be89-59e729f75feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run without for loop\n",
    "forest_height_2020_uri = f'{general_uri}202307_revision/test_1x1_deg/50N_010E_1deg_FH_2020.tif'\n",
    "forest_height_2021_uri = f'{general_uri}202307_revision/test_1x1_deg/50N_010E_1deg_FH_2021.tif'\n",
    "forest_loss_detection_uri = f'{general_uri}202307_revision/test_1x1_deg/50N_010E_1deg_DFL_2020.tif'\n",
    "\n",
    "driver_uri = \"s3://gfw2-data/forest_change/GLAD_Europe_resubmission__202306/test_1x1_deg/50N_010E_1deg_tree_cover_loss_driver_processed.tif\"\n",
    "peat_uri = \"s3://gfw2-data/forest_change/GLAD_Europe_resubmission__202306/test_1x1_deg/50N_010E_1deg_peat_mask_processed.tif\"\n",
    "tclf_uri = \"s3://gfw2-data/forest_change/GLAD_Europe_resubmission__202306/test_1x1_deg/50N_010E_1deg_tree_cover_loss_fire_processed.tif\"\n",
    "# land_cover_uri = ...\n",
    "# planted_forest_uri = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff9797-8b18-4a4b-8c51-f813a4fe3a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run without for loop\n",
    "forest_height_2020 = get_tile_dataset(forest_height_2020_uri, name=\"forest_height_2020\")\n",
    "forest_height_2021 = get_tile_dataset(forest_height_2021_uri, name=\"forest_height_2021\")\n",
    "forest_loss_detection_previous_year = get_tile_dataset(forest_loss_detection_uri, name=\"forest_height_current_year\")\n",
    "\n",
    "# driver = get_tile_dataset(driver_uri, name=\"driver\")\n",
    "# peat = get_tile_dataset(peat_uri, name=\"peat\")\n",
    "# TCLF = get_tile_dataset(tclf_uri, name=\"tclf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e86512e-c421-4ca1-bbaf-d01646f29e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Run without for loop\n",
    "# Some sample dask operations\n",
    "# print(forest_height_2020)\n",
    "print(forest_height_2020.mean().compute())\n",
    "print(forest_height_2021.mean().compute())\n",
    "print(forest_loss_detection_previous_year.mean().compute())\n",
    "# forest_height_2021.mean().compute()\n",
    "# print(forest_height_2021.mean().compute())\n",
    "# print(driver)        \n",
    "# print(driver.mean().compute())\n",
    "# print(forest_height_2020.where(driver > 1).mean().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c6fe2-becd-41f6-beff-a22489d32a61",
   "metadata": {},
   "source": [
    "You'll likely want to make a class that encapsulates all the pixel data you'll pass into your decision tree for classification. This will make it much easier to read how your decision tree uses the pixel data, and also will give you a place to do any modifications to the input data or add additional fields based off of the input data you may want to re-use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c0cbc0-e769-42a1-b3ae-42e208e25d6d",
   "metadata": {},
   "source": [
    "I didn't fill this out for now, but this is just a stub for the class we discussed with Gary. It will take in your above decision factors class, which includes all the data in your layers at one pixel, and classify it using your decision tree logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972d1738-bfd8-4a5e-8def-487309e3922c",
   "metadata": {},
   "source": [
    "So, the xrspatial.local.combine method I mentioned doesn't seem to work very well on large arrays (it's not lazily computed), and I noticed they plan to deprecate it. Not sure if they're going to replace, but this method works just as well, but it's a little more confusing to understand.\n",
    "\n",
    "What we'd like to do is to smush all your pixel across many layers into a single integer. We'd then like to be able to easily convert it back to the layer data later. This will make it much easier and faster to process your data in the decision tree.\n",
    "\n",
    "NumPy has a nifty and very performant way of doing this called ravel_multi_index: https://numpy.org/doc/stable/reference/generated/numpy.ravel_multi_index.html\n",
    "\n",
    "For this kind of problem, we typically stack all our raster layers on top of each other to create a 3D array. Imagine instead we throw away the geospatial component and reshape thee data as an N-dimensional array, one dimension for each layer. The length of each dimension is the highest value of each layer (e.g. for boolean layer it's 1, for a categorical layer it'd be the number of categories).\n",
    "\n",
    "You can map a pixel in your 3D geospatial array to this N-d array by putting it at the index of all its layer values. So if you have 2 boolean layers and a categorical layer, and have a pixel with values (true, false, 3), in the N-d array, its location would be arr[1][0][3].\n",
    "\n",
    "Now, in NumPy, when we want to ravel an array, this means we view a multidimensional array and turn it into a 1D array by simply reading each row in order, wrapping around the end of row to the neext row. If you have a 2x8 array, you can ravel it by reading the first row of 8 and then the second row of 8. E.g. in the raveled view, arr[1][3] would actually be indexed as arr[11].\n",
    "\n",
    "Ok, bearing with me? Putting these together, you can convert values in your N-d array into a single integer by converting them to the index in their raveled view. So in the above example, arr[1][0][3] can be converted to the integer 5 (if I have the orderr right), because it'd be the 5th index if you called ravel(arr)[5].\n",
    "\n",
    "This provides a very convenient and fast way to convert multidimensional into an integer and back, as long as you know the max dimensions of each layer. So in index_dims below, you'll want to fill out the max dimension for each layer in the order you'll stack them. For boolean layers, it'll just be 1, for categorical layers, it'll be the max category number, and for temporal layers, it'll be the max time. If you don't know it, you can can also just use the max value for the data type, as long as its not int64 (so uint8 would 256). If you have float layers you use here, let me know - this may not work as well, but didn't notice any in your decision tree.\n",
    "\n",
    "Despite all that explanation of what's going on, you can basically just call the function I made below, which will map stack of layers into that raveled index and return it as new array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea2076-8177-4fba-9ded-7201ba4d21ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run without for loop\n",
    "\n",
    "index_dims = (40, 40)\n",
    "\n",
    "def consolidate_to_one_dimensional_index(chunk):\n",
    "    return xr.DataArray(np.ravel_multi_index([chunk.forest_height_2020.data, chunk.forest_height_2021.data], index_dims), coords=chunk.coords, dims=chunk.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd7a3de-38fe-426d-b633-24f850147ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run without for loop\n",
    "\n",
    "# you'll want to combine them all into one xarray dataset, which is just a way to group arrays that\n",
    "# are aligned on the same coordinates\n",
    "decision_tree_ds = xr.Dataset({\n",
    "    \"forest_height_2020\": forest_height_2020, \n",
    "    \"forest_height_2021\": forest_height_2021,\n",
    "    # \"drivers\": driver\n",
    "})\n",
    "\n",
    "decision_tree_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ececb39-7e2b-476f-992a-a873931d7b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run without for loop\n",
    "\n",
    "# use the function above to map your dataset to that 1D index\n",
    "decision_tree_index = decision_tree_ds.map_blocks(consolidate_to_one_dimensional_index, template=forest_height_2020.copy())\n",
    "#decision_tree_index.compute()\n",
    "# decision_tree_index.mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40553cef-d17e-4a2e-b86e-e1f3b48f9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run without for loop\n",
    "\n",
    "# Save the decision tree index array to raster\n",
    "decision_tree_index.rio.to_raster(f'{local_out_dir}decision_tree_index_2021__20230814_not_for_loop.tif', compress='DEFLATE', dtype='uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f171324-be3c-461a-84cf-35c6d7a53c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run without for loop\n",
    "\n",
    "# find all unique index values across the tile\n",
    "unique_indices = dar.unique(decision_tree_index.data)\n",
    "unique_indices.compute_chunk_sizes()   #Added to resolve unknown chunk size error: https://docs.dask.org/en/latest/array-chunks.html#unknown-chunks\n",
    "unique_indices = unique_indices.compute()\n",
    "# print(unique_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c8b3a6-2e6e-4fd6-b016-4911b24ed742",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Run without for loop\n",
    "\n",
    "def classify_index(index):\n",
    "    decisionFactors = ForestStateDecisionFactors(*np.unravel_index(index, index_dims))\n",
    "    return ForestStateDecisionTree.classify(decisionFactors)\n",
    "\n",
    "forest_states_per_index = [classify_index(index) for index in unique_indices]\n",
    "# forest_states_per_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d370b1d2-14a6-47cc-b08c-8af59004a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# you'll call this function on each unique index to convert the index back to your layer values and classify them to a forest state\n",
    "\n",
    "@dask.delayed\n",
    "def classify_index(index):\n",
    "    decisionFactors = ForestStateDecisionFactors(*np.unravel_index(index, index_dims))\n",
    "    return ForestStateDecisionTree.classify(decisionFactors)\n",
    "\n",
    "forest_states_per_index = dask.compute(*[classify_index(index) for index in unique_indices])\n",
    "# forest_states_per_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aee916-41c1-4bac-9901-ff130c54bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Does not work because ndarray does not accept .apply(). This was suggested by Justin\n",
    "\n",
    "def classify_index(index):\n",
    "    decisionFactors = ForestStateDecisionFactors(*np.unravel_index(index, index_dims))\n",
    "    return ForestStateDecisionTree.classify(decisionFactors)\n",
    "\n",
    "forest_states_per_index = unique_indices.apply(classify_index)\n",
    "forest_states_per_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b72f9de-02cf-473e-af6e-9a8ba2b977c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Run without for loop\n",
    "\n",
    "# swap the indices for their corresponding forest state\n",
    "\n",
    "forest_states = xrspatial.classify.reclassify(\n",
    "    decision_tree_index.squeeze(\"band\"),\n",
    "    bins=unique_indices, \n",
    "    new_values=forest_states_per_index,\n",
    "    name=\"forest_states\"\n",
    ")\n",
    "forest_states_final = forest_states.compute()\n",
    "forest_states_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10028103-6754-4530-a884-f72036d6a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_states_final.mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f62eb-3ccd-4c02-b809-49f6898456de",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_states_final.rio.to_raster(f'{local_out_dir}forest_states_2021__20230814_not_for_loop.tif', compress='DEFLATE', dtype='uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7875fb-1d3f-414f-8ca2-9e739271d203",
   "metadata": {},
   "source": [
    "<font size=\"4\">Running with for loop</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee168db9-4376-4ecf-bf2a-1bc67f6ba5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with for loop\n",
    "\n",
    "index_dims = (40, 40)\n",
    "\n",
    "def consolidate_to_one_dimensional_index_for_loop(chunk):\n",
    "    return xr.DataArray(np.ravel_multi_index([chunk.forest_height_previous_year.data, chunk.forest_height_current_year.data], index_dims), coords=chunk.coords, dims=chunk.dims)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4024affb-db0c-4f04-b404-4f8fd2e3236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Run with for loop\n",
    "# you'll call this function on each unique index to convert the index back to your layer values and classify them to a forest state    \n",
    "\n",
    "def classify_index(index):\n",
    "    decisionFactors = ForestStateDecisionFactors(*np.unravel_index(index, index_dims))\n",
    "    return ForestStateDecisionTree.classify(decisionFactors)\n",
    "\n",
    "# forest_states_per_index = [classify_index(index) for index in unique_indices]\n",
    "# forest_states_per_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c8138d-2045-46d6-96c2-574bb97928c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tile_id_list = [\"50N_010E\"]\n",
    "\n",
    "years = [2019, 2020, 2021]\n",
    "# years = [2019]\n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d\")\n",
    "\n",
    "\n",
    "for tile_id in tile_id_list:\n",
    "    \n",
    "#     driver_uri ='{0}{1}_1deg_tree_cover_loss_driver_processed.tif'.format(general_uri, tile_id)\n",
    "#     peat_uri = '{0}{1}_1deg_peat_mask_processed.tif'.format(general_uri, tile_id)\n",
    "#     tclf_uri = '{0}{1}_1deg_tree_cover_loss_fire_processed.tif'.format(general_uri, tile_id)\n",
    "#     land_cover_uri = ...\n",
    "#     planted_forest_uri = ...\n",
    "    \n",
    "#     driver = get_tile_dataset(driver_uri, name=\"driver\")\n",
    "#     peat = get_tile_dataset(peat_uri, name=\"peat\")\n",
    "#     tclf = get_tile_dataset(tclf_uri, name=\"tclf\")\n",
    "#     land_cover = get_tile_dataset(tclf_uri, name=\"land_cover_uri\")\n",
    "#     planted_forest = get_tile_dataset(tclf_uri, name=\"planted_forest_uri\")\n",
    "\n",
    "    for year in years:\n",
    "        \n",
    "        start = time.time()\n",
    "              \n",
    "        current_year = year\n",
    "        previous_year = current_year - 1\n",
    "        print(\"Previous year: \" + str(previous_year))\n",
    "        print(\"Current year: \"+ str(current_year))\n",
    "               \n",
    "        forest_height_previous_year_uri = f'{general_uri}202307_revision/test_1x1_deg/{tile_id}_1deg_FH_{previous_year}.tif'\n",
    "        forest_height_current_year_uri = f'{general_uri}202307_revision/test_1x1_deg/{tile_id}_1deg_FH_{current_year}.tif'\n",
    "        forest_loss_detection_uri = f'{general_uri}202307_revision/test_1x1_deg/{tile_id}_1deg_DFL_{previous_year}.tif'\n",
    "        \n",
    "        print(forest_height_previous_year_uri)\n",
    "        print(forest_height_current_year_uri)\n",
    "        print(forest_loss_detection_uri)\n",
    "               \n",
    "        forest_height_previous_year = get_tile_dataset(forest_height_previous_year_uri, name=\"forest_height_previous_year\")\n",
    "        forest_height_current_year = get_tile_dataset(forest_height_current_year_uri, name=\"forest_height_current_year\")\n",
    "        forest_loss_detection_previous_year = get_tile_dataset(forest_loss_detection_uri, name=\"forest_height_current_year\")\n",
    "        \n",
    "        print(forest_height_previous_year.mean().compute())\n",
    "        print(forest_height_current_year.mean().compute())\n",
    "\n",
    "          \n",
    "        # you'll want to combine them all into one xarray dataset, which is just a way to group arrays that\n",
    "        # are aligned on the same coordinates\n",
    "        decision_tree_ds = xr.Dataset({\n",
    "            \"forest_height_previous_year\": forest_height_previous_year, \n",
    "            \"forest_height_current_year\": forest_height_current_year\n",
    "        })\n",
    "        \n",
    "        # use the function above to map your dataset to that 1D index\n",
    "        print(\"Making index matrix...\")\n",
    "        decision_tree_index = decision_tree_ds.map_blocks(consolidate_to_one_dimensional_index_for_loop, template=forest_height_previous_year.copy())\n",
    "        \n",
    "        # # Save the decision tree index array to raster\n",
    "        # decision_tree_index_matrix = decision_tree_index.compute()\n",
    "        # print(\"decision_tree_index\")\n",
    "        # print(decision_tree_index_matrix)\n",
    "        # decision_tree_index_matrix.rio.to_raster(f'{local_out_dir}{tile_id}_1deg_decision_tree_index_{current_year}__{timestr}.tif', compress='DEFLATE', dtype='uint16')\n",
    "\n",
    "        # find all unique index values across the tile\n",
    "        print(\"Finding unique indices...\")\n",
    "        unique_indices = dar.unique(decision_tree_index.data)\n",
    "        unique_indices.compute_chunk_sizes()   #Added to resolve unknown chunk size error: https://docs.dask.org/en/latest/array-chunks.html#unknown-chunks\n",
    "        unique_indices=unique_indices.compute()\n",
    "        # print(\"Unique indices:\")\n",
    "        # print(unique_indices)\n",
    "        \n",
    "        print(\"Converting unique index list to forest state list...\")\n",
    "        forest_states_per_index = [classify_index(index) for index in unique_indices]\n",
    "\n",
    "        # print(\"forest_states_per_index\")\n",
    "        # print(forest_states_per_index)\n",
    "\n",
    "        print(\"Creating forest state matrix...\")\n",
    "        forest_states = xrspatial.classify.reclassify(\n",
    "            decision_tree_index.squeeze(\"band\"),\n",
    "            bins=unique_indices, \n",
    "            new_values=forest_states_per_index,\n",
    "            name=\"forest_states\"\n",
    "        )\n",
    "        forest_states_final = forest_states.compute()\n",
    "        forest_states_final\n",
    "\n",
    "        print(\"Saving forest state raster...\")\n",
    "        forest_states_final.rio.to_raster(f'{local_out_dir}{tile_id}_1deg_FH_forest_states_{current_year}__{timestr}.tif', compress='DEFLATE', dtype='uint8')\n",
    "        \n",
    "        end = time.time()\n",
    "        print(\"Elapsed time to generate forest states in tile_id {0} for {1} : \".format(tile_id, current_year), round(end-start))\n",
    "\n",
    "#         # # now you can also swap your forest states for emissions/removals factors\n",
    "#         # emissions = (forest_states[forest_states == 1] * (full_biomass + non_co2_peat + non_co2_fire)) + \n",
    "#         #                 (forest_states[forest_states == 2] * partial_biomass + non_co2_peat + non_co2_fire) + ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61703e45-c2c6-4209-9dca-f3b2e52eabef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c73dc-0f36-4f89-8141-e6950426f5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa3ed53-d72e-478f-93ae-b1b8612a2784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc877560-dad4-441f-836b-169e6cdf5701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
