{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'   # Suppresses some warning about geopandas\n",
    "import geopandas as gpd\n",
    "\n",
    "# scipy basics\n",
    "import numpy as np\n",
    "import botocore\n",
    "from osgeo import gdal      # Necessary to do this import to get rasterio to import\n",
    "import rasterio as rio\n",
    "import rasterio.features\n",
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "import time\n",
    "\n",
    "# dask/parallelization libraries\n",
    "import coiled\n",
    "import dask\n",
    "import dask.array as dar\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "import xrspatial.local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Making cloud and local clusters</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coiled_cluster = coiled.Cluster(\n",
    "    n_workers=5,\n",
    "    use_best_zone=True, \n",
    "    compute_purchase_option=\"spot_with_fallback\",\n",
    "    idle_timeout=\"20 minutes\",\n",
    "    # name=\"DGibbs Europe height flux model\", \n",
    "    account='jterry64'   # Necessary to use the AWS environment that Justin set up in Coiled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coiled cluster (cloud run)\n",
    "coiled_client = coiled_cluster.get_client()\n",
    "coiled_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local cluster (local run). Doesn't work-- .compute() method kill workers for unknown reasons. Can't use for now.\n",
    "# local_cluster = LocalCluster(silence_logs=False)\n",
    "local_cluster = LocalCluster()\n",
    "local_client = Client(local_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Local single-process cluster (local run). Will run .compute() on just one process, not a whole cluster.\n",
    "# local_client = Client(processes=False)\n",
    "# local_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Shutting down cloud and local clusters</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coiled_cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Analysis</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Paths and functions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General paths and constants\n",
    "\n",
    "general_uri = 's3://gfw2-data/forest_change/GLAD_Europe_height_data/'\n",
    "\n",
    "random_data_uri = 's3://gfw2-data/forest_change/GLAD_Europe_height_data/dummy_random_data__20230901/'\n",
    "\n",
    "local_out_dir = 'C:\\\\GIS\\\\Carbon_model_Europe\\\\outputs\\\\'\n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d\")\n",
    "\n",
    "height_cutoff = 5\n",
    "\n",
    "chunk_length = 1000\n",
    "\n",
    "tile_size = 1      # Tile size in degrees is from the top left of the tile. 10 is a full tile. Anything smaller is a subset of that.\n",
    "\n",
    "current_year = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads tile\n",
    "# From https://notebooks-staging.wri.org/user/dagibbs22/lab/tree/msims/biodiversity_global_stats.ipynb\n",
    "# Bounding box use comes from https://github.com/corteva/rioxarray/issues/115#issuecomment-1206673437 and https://corteva.github.io/rioxarray/html/examples/clip_box.html. \n",
    "\n",
    "# Tile size is from the top left of the tile\n",
    "def get_tile_dataset(uri, name, template=None, tile_size=10):\n",
    "    # If the input tile_size is too large, it reverts to 10 (standard tile size)\n",
    "    if tile_size > 10:\n",
    "        tile_size = 10\n",
    "    try:\n",
    "        raster = rioxarray.open_rasterio(uri, chunks=chunk_length, default_name=name)\n",
    "        # raster = rioxarray.open_rasterio(uri, default_name=name)\n",
    "        raster_extent = raster.rio.bounds()\n",
    "        minx=raster_extent[0]\n",
    "        miny=raster_extent[1]\n",
    "        maxx=raster_extent[2]\n",
    "        maxy=raster_extent[3]\n",
    "        return raster.rio.clip_box(minx=minx, miny=maxy-tile_size, maxx=minx+tile_size, maxy=maxy).squeeze(\"band\")\n",
    "    except rasterio.errors.RasterioIOError as e:\n",
    "        if template is not None:\n",
    "            return xr.zeros_like(template)\n",
    "        else:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Reading in data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://gfw2-data/forest_change/GLAD_Europe_height_data/202307_revision/test_10x10_deg/50N_010E_FH_2018.tif\n",
      "s3://gfw2-data/climate/carbon_model/other_emissions_inputs/burn_year/burn_year_10x10_clip/ba_2017_50N_010E.tif\n",
      "s3://gfw2-data/climate/carbon_model/other_emissions_inputs/burn_year/burn_year_10x10_clip/ba_2018_50N_010E.tif\n"
     ]
    }
   ],
   "source": [
    "# Input file locations\n",
    "\n",
    "# forest_height_previous_uri = f'{general_uri}202307_revision/FH_2020.tif'\n",
    "# forest_height_current_uri = f'{general_uri}202307_revision/FH_2021.tif'\n",
    "# forest_loss_detection_uri = f'{general_uri}202307_revision/DFL_2021.tif'\n",
    "\n",
    "forest_height_2016_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_FH_2016.tif'\n",
    "forest_height_2017_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_FH_2017.tif'\n",
    "forest_height_2018_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_FH_2018.tif'\n",
    "forest_height_2019_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_FH_2019.tif'\n",
    "forest_height_2020_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_FH_2020.tif'\n",
    "forest_height_2021_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_FH_2021.tif'\n",
    "\n",
    "# Using 10x10 degree rasters of actual data\n",
    "forest_height_previous_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_FH_{current_year-1}.tif'\n",
    "forest_height_current_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_FH_{current_year}.tif'\n",
    "forest_loss_detection_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_DFL_{current_year}.tif'\n",
    "\n",
    "driver_uri = \"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/tree_cover_loss_drivers/processed/drivers_2022/20230407/50N_010E_tree_cover_loss_driver_processed.tif\"\n",
    "planted_forest_type_uri = \"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/planted_forest_type/SDPT_v1/standard/20200730/50N_010E_plantation_type_oilpalm_woodfiber_other_unmasked.tif\"\n",
    "peat_uri = \"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/peatlands/processed/20230315/50N_010E_peat_mask_processed.tif\"\n",
    "\n",
    "landcover_composite_2000_uri = \"s3://gfw2-data/landcover/composite/2000/50N_010E_composite_landcover_2000.tif\"\n",
    "landcover_composite_2005_uri = \"s3://gfw2-data/landcover/composite/2005/50N_010E_composite_landcover_2005.tif\"\n",
    "landcover_composite_2010_uri = \"s3://gfw2-data/landcover/composite/2010/50N_010E_composite_landcover_2010.tif\"\n",
    "landcover_composite_2015_uri = \"s3://gfw2-data/landcover/composite/2015/50N_010E_composite_landcover_2015.tif\"\n",
    "landcover_composite_2020_uri = \"s3://gfw2-data/landcover/composite/2020/50N_010E_composite_landcover_2020.tif\"\n",
    "\n",
    "cropland_NE_2003_uri = \"s3://gfw2-data/landcover/cropland/2003/raw/Global_cropland_NE_2003.tif\"\n",
    "cropland_NE_2007_uri = \"s3://gfw2-data/landcover/cropland/2007/raw/Global_cropland_NE_2007.tif\"\n",
    "cropland_NE_2011_uri = \"s3://gfw2-data/landcover/cropland/2011/raw/Global_cropland_NE_2011.tif\"\n",
    "cropland_NE_2015_uri = \"s3://gfw2-data/landcover/cropland/2015/raw/Global_cropland_NE_2015.tif\"\n",
    "cropland_NE_2019_uri = \"s3://gfw2-data/landcover/cropland/2019/raw/Global_cropland_NE_2019.tif\"\n",
    "\n",
    "ba_two_before_uri = f's3://gfw2-data/climate/carbon_model/other_emissions_inputs/burn_year/burn_year_10x10_clip/ba_{current_year-2}_50N_010E.tif'\n",
    "ba_one_before_uri = f's3://gfw2-data/climate/carbon_model/other_emissions_inputs/burn_year/burn_year_10x10_clip/ba_{current_year-1}_50N_010E.tif'\n",
    "\n",
    "# # Using random data\n",
    "# forest_height_previous_uri = f'{random_data_uri}50N_010E_FH_2020_random_data.tif'\n",
    "# forest_height_current_uri = f'{random_data_uri}50N_010E_FH_2021_random_data.tif'\n",
    "# forest_loss_detection_uri = f'{random_data_uri}50N_010E_DFL_2021_random_data.tif'\n",
    "\n",
    "# driver_uri = f'{random_data_uri}50N_010E_tree_cover_loss_driver_processed_random_data.tif'\n",
    "# planted_forest_type_uri = f'{random_data_uri}50N_010E_plantation_type_oilpalm_woodfiber_other_unmasked_random_data.tif'\n",
    "# peat_uri = f'{random_data_uri}50N_010E_peat_mask_processed_random_data.tif'\n",
    "\n",
    "# ba_2017_uri = f'{random_data_uri}50N_010E_burned_area_2017_random_data.tif'\n",
    "# ba_2018_uri = f'{random_data_uri}50N_010E_burned_area_2018_random_data.tif'\n",
    "# ba_2019_uri = f'{random_data_uri}50N_010E_burned_area_2019_random_data.tif'\n",
    "# ba_2020_uri = f'{random_data_uri}50N_010E_burned_area_2020_random_data.tif'\n",
    "# ba_2021_uri = f'{random_data_uri}50N_010E_burned_area_2021_random_data.tif'\n",
    "\n",
    "print(forest_height_previous_uri)\n",
    "print(ba_two_before_uri)\n",
    "print(ba_one_before_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads input files\n",
    "\n",
    "forest_height_2016 = get_tile_dataset(forest_height_2016_uri, name=\"forest_height_2016\", tile_size=tile_size)\n",
    "forest_height_2017 = get_tile_dataset(forest_height_2017_uri, name=\"forest_height_2017\", tile_size=tile_size)\n",
    "forest_height_2018 = get_tile_dataset(forest_height_2018_uri, name=\"forest_height_2018\", tile_size=tile_size)\n",
    "forest_height_2019 = get_tile_dataset(forest_height_2019_uri, name=\"forest_height_2019\", tile_size=tile_size)\n",
    "forest_height_2020 = get_tile_dataset(forest_height_2020_uri, name=\"forest_height_2020\", tile_size=tile_size)\n",
    "forest_height_2021 = get_tile_dataset(forest_height_2021_uri, name=\"forest_height_2021\", tile_size=tile_size)\n",
    "\n",
    "forest_height_previous = get_tile_dataset(forest_height_previous_uri, name=\"forest_height_previous\", tile_size=tile_size)\n",
    "forest_height_current = get_tile_dataset(forest_height_current_uri, name=\"forest_height_current\", tile_size=tile_size)\n",
    "forest_loss_detection = get_tile_dataset(forest_loss_detection_uri, name=\"forest_loss_detection\", tile_size=tile_size)\n",
    "\n",
    "driver = get_tile_dataset(driver_uri, name=\"driver\", tile_size=tile_size)\n",
    "planted_forest = get_tile_dataset(planted_forest_type_uri, name=\"planted_forest\", tile_size=tile_size)\n",
    "peat = get_tile_dataset(peat_uri, name=\"peat\", tile_size=tile_size)\n",
    "\n",
    "LC_previous = get_tile_dataset(landcover_composite_2015_uri, name=\"LC_previous\", tile_size=tile_size)\n",
    "LC_next = get_tile_dataset(landcover_composite_2020_uri, name=\"LC_next\", tile_size=tile_size)\n",
    "\n",
    "cropland_previous = get_tile_dataset(cropland_NE_2019_uri, name=\"cropland_previous\", tile_size=tile_size)\n",
    "\n",
    "ba_two_before = get_tile_dataset(ba_two_before_uri, name=\"ba_two_before\", tile_size=tile_size)\n",
    "ba_one_before = get_tile_dataset(ba_two_before_uri, name=\"ba_one_before\", tile_size=tile_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Recent burned area</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping burned area in two preceding years\n",
      "CPU times: total: 750 ms\n",
      "Wall time: 1.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Maps raster of burned area in two preceding years\n",
    "\n",
    "# xarray dataarray of 0s that has the properties of forest_height_current\n",
    "burned_area_recent_blank = xr.zeros_like(forest_height_current)\n",
    "\n",
    "print(\"Mapping burned area in two preceding years\")\n",
    "burned_area_recent_array = dask.array.where(np.logical_or(ba_two_before != 0, ba_one_before != 0), 1, burned_area_recent_blank).compute()\n",
    "\n",
    "# Converts the burned_area_recent numpy array to a xarray dataarray\n",
    "burned_area_recent = xr.DataArray(burned_area_recent_array, dims=('y', 'x'), \n",
    "                                  coords={'x': burned_area_recent_blank['x'], 'y': burned_area_recent_blank['y']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exports dataarray to raster\n",
    "burned_area_recent.rio.set_crs(\"EPSG:4326\")\n",
    "burned_area_recent.rio.to_raster(f'{local_out_dir}burned_area_recent_{current_year}__{timestr}_{tile_size}_deg.tif', compress='DEFLATE', dtype='uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Final year of forest</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines all the dataarrays into a dataset\n",
    "\n",
    "forest_height_ds = xr.Dataset({\n",
    "    \"forest_height_2016\": forest_height_2016, \n",
    "    \"forest_height_2017\": forest_height_2017, \n",
    "    \"forest_height_2018\": forest_height_2018, \n",
    "    \"forest_height_2019\": forest_height_2019,\n",
    "    \"forest_height_2020\": forest_height_2020, \n",
    "    \"forest_height_2021\": forest_height_2021, \n",
    "})\n",
    "\n",
    "# forest_height_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping forest presence for 2016\n",
      "Mapping forest presence for 2017\n",
      "Mapping forest presence for 2018\n",
      "Mapping forest presence for 2019\n",
      "Mapping forest presence for 2020\n",
      "Mapping forest presence for 2021\n",
      "CPU times: total: 39.1 s\n",
      "Wall time: 49.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Maps forest presence (>=5 m) for each year (each dataarray)\n",
    "\n",
    "def map_forests(data_array, dataset):\n",
    "    \n",
    "    year = data_array.name[-4:]\n",
    "    print(f\"Mapping forest presence for {year}\") \n",
    " \n",
    "    # xarray dataarray of 0s that has the properties of input dataarray\n",
    "    forest_presence_zeros = xr.zeros_like(data_array)\n",
    "\n",
    "    # Masks pixels with height >= 5 m\n",
    "    forest_presence = dask.array.where((data_array >= height_cutoff), int(year), forest_presence_zeros).compute()\n",
    "\n",
    "    # Converts numpy array to xarray dataarray\n",
    "    forest_presence_da = xr.DataArray(forest_presence, dims=('y', 'x'), coords={'x': data_array['x'], 'y': data_array['y']})\n",
    "    \n",
    "    # Exports dataarray to raster\n",
    "    forest_presence_da.rio.set_crs(\"EPSG:4326\")\n",
    "    forest_presence_da.rio.to_raster(f'{local_out_dir}forest_presence_{year}__{timestr}_{tile_size}_deg.tif', compress='DEFLATE', dtype='uint16')\n",
    "\n",
    "    return forest_presence_da\n",
    "\n",
    "# Applies the map_forests function to every dataarray in the dataset\n",
    "forest_presence_ds = forest_height_ds.map(map_forests, dataset=forest_height_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renames the forest presence dataarrays in the forest presence dataset\n",
    "\n",
    "for variable in forest_presence_ds.data_vars:\n",
    "    year = variable[-4:]\n",
    "    forest_presence_ds = forest_presence_ds.rename({variable: f'forest_presence_{year}'})\n",
    "# forest_presence_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the max value in multiple stacked data arrays within a dataset\n",
    "\n",
    "# https://stackoverflow.com/questions/65149355/is-there-a-faster-way-to-sum-xarray-dataset-variables\n",
    "# vars_to_combine = [\"forest_presence_2016\", \"forest_presence_2017\", \"forest_presence_2018\", \"forest_presence_2019\", \"forest_presence_2020\", \"forest_presence_2021\"]\n",
    "\n",
    "vars = list(forest_presence_ds.keys())\n",
    "\n",
    "final_forest_year = forest_presence_ds[vars].to_array().max(\"variable\").compute()\n",
    "# final_forest_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_forest_year.rio.set_crs(\"EPSG:4326\")\n",
    "final_forest_year.rio.to_raster(f'{local_out_dir}final_forest_year__{timestr}_{tile_size}_deg.tif', compress='DEFLATE', dtype='uint16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Annual classification</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts all the dataarrays into a dataset\n",
    "\n",
    "decision_tree_ds = xr.Dataset({\n",
    "    \"forest_height_previous\": forest_height_previous, \n",
    "    \"forest_height_current\": forest_height_current,\n",
    "    \"forest_loss_detection\": forest_loss_detection,\n",
    "    \"driver\": driver,\n",
    "    \"planted_forest\": planted_forest,\n",
    "    \"peat\": peat,\n",
    "    \"LC_previous\": LC_previous,\n",
    "    \"LC_next\": LC_next,\n",
    "    \"burned_area_recent\": burned_area_recent,\n",
    "    \"final_forest_year\": final_forest_year\n",
    "})\n",
    "\n",
    "# decision_tree_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies forest state rules to the forest_state_zeros array of 0s\n",
    "def classify():\n",
    "    \n",
    "    print(\"Assigning forest states\")\n",
    "\n",
    "    maintained = (forest_height_previous >= height_cutoff) & (forest_height_current >= height_cutoff)\n",
    "    gained = (forest_height_previous < height_cutoff) & (forest_height_current >= height_cutoff)\n",
    "    lost = (((forest_height_previous >= height_cutoff) & (forest_height_current < height_cutoff)) | (forest_loss_detection == 1))\n",
    "    no_forest = (forest_height_previous < height_cutoff) & (forest_height_current < height_cutoff)\n",
    "\n",
    "    grassland_next = (((LC_next >= 2) & (LC_next <= 26)) | ((LC_next >= 102) & (LC_next <= 126)))\n",
    "    \n",
    "    forest_next = (((LC_next >= 27) & (LC_next <= 48)) | ((LC_next >= 127) & (LC_next <= 148)))\n",
    "\n",
    "    other_next = ((grassland_next == 0) & (forest_next == 0))\n",
    "\n",
    "    cropland_previous = (LC_previous == 244)\n",
    "    cropland_next = (LC_next == 244)\n",
    "\n",
    "    builtup_previous = (LC_previous == 250)\n",
    "    builtup_next = (LC_next == 250)\n",
    "    \n",
    "    grassland_forest_previous = (((LC_previous >= 2) & (LC_previous <= 48)) | ((LC_previous >= 102) & (LC_previous <= 148)))\n",
    "    grassland_forest_next = (((LC_next >= 2) & (LC_next <= 48)) | ((LC_next >= 102) & (LC_next <= 148)))  \n",
    "\n",
    "    forestry = (driver == 3)\n",
    "    \n",
    "    non_sdpt_forestry = (forestry & (grassland_forest_previous | grassland_forest_next) & (cropland_previous == 0) & (cropland_next == 0))\n",
    "    \n",
    "\n",
    "    print(\"Maintained branch\")\n",
    "    forest_state_array = dask.array.where(\n",
    "        maintained, 1, forest_state_zeros)     #maintained\n",
    "\n",
    "    print(\"Gain branch\")\n",
    "    forest_state_array = dask.array.where(gained, \n",
    "        2, forest_state_array)    #gained\n",
    "\n",
    "    print(\"Loss branch\")\n",
    "\n",
    "    ###Land use change (haven't built out peat and fire branches yet)\n",
    "    #Loss:no SDPT:no non-SDPT forestry:no later forest:cropland next\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year < int(year)) & (forest_next == 0))\n",
    "        & cropland_next, 31111, forest_state_array)\n",
    "    #Loss:no SDPT:no non-SDPT forestry:no later forest:settlement next\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year < int(year)) & (forest_next == 0))\n",
    "        & builtup_next, 31112, forest_state_array)\n",
    "    #Loss:no SDPT:no non-SDPT forestry:no later forest:grassland next\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year < int(year)) & (forest_next == 0))\n",
    "        & grassland_next, 31113, forest_state_array)\n",
    "    #Loss:no SDPT:no non-SDPT forestry:no later forest: other land cover next\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year < int(year)) & (forest_next == 0))\n",
    "        & ((cropland_next == 0) & (builtup_next == 0) & (grassland_next == 0)), 31114, forest_state_array)\n",
    "\n",
    "    ### Land cover change\n",
    "    #Loss:no SDPT:no non-SDPT forestry:later forest:forest next:no recent fire:no peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next) \n",
    "        & forest_next & (burned_area_recent == 0) & (peat == 0), 3112111, forest_state_array)\n",
    "    #Loss:no SDPT:no non-SDPT forestry:later forest:forest next:no recent fire:peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next)\n",
    "        & forest_next & (burned_area_recent == 0) & (peat == 1), 3112112, forest_state_array)\n",
    "    #Loss:no SDPT:no non-SDPT forestry:later forest:forest next:recent fire:no peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next)\n",
    "        & forest_next & (burned_area_recent == 1) & (peat == 0), 3112121, forest_state_array)\n",
    "    #Loss:no SDPT:no non-SDPT forestry:later forest:forest next:recent fire:peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next)\n",
    "        & forest_next & (burned_area_recent == 1) & (peat == 1), 3112122, forest_state_array)\n",
    "\n",
    "    #Loss:no SDPT:no non-SDPT forestry:later forest:grassland next:no recent fire:no peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next)\n",
    "        & grassland_next & (burned_area_recent == 0) & (peat == 0), 3112211, forest_state_array)   \n",
    "    #Loss:no SDPT:no non-SDPT forestry:later forest:grassland next:no recent fire:peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next)\n",
    "        & grassland_next & (burned_area_recent == 0) & (peat == 1), 3112212, forest_state_array)\n",
    "    #Loss:no SDPT:no non-SDPT forestry:later forest:grassland next:recent fire:no peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next)\n",
    "        & grassland_next & (burned_area_recent == 1) & (peat == 0), 3112221, forest_state_array)   \n",
    "    #Loss:no SDPT:no non-SDPT forestry:later forest:grassland next:recent fire:peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next) \n",
    "        & grassland_next & (burned_area_recent == 1) & (peat == 1), 3112222, forest_state_array)   \n",
    "    \n",
    "    \n",
    "    #Loss:no SDPT:no non-SDPT forestry:later forest:other LC next:no recent fire:no peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next)\n",
    "        & other_next & (burned_area_recent == 0) & (peat == 0), 3112311, forest_state_array)\n",
    "    #Loss:no SDPT:no non-SDPT forestry:later forest:other LC next:no recent fire:peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next) \n",
    "        & other_next & (burned_area_recent == 0) & (peat == 1), 3112312, forest_state_array)   \n",
    "    #Loss:no SDPT:no non-SDPT forestry:later forest:other LC next:recent fire:no peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next)\n",
    "        & other_next & (burned_area_recent == 1) & (peat == 0), 3112321, forest_state_array)   \n",
    "    #Loss:no SDPT:no non-SDPT forestry:later forest:other LC next:no recent fire:no peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next)\n",
    "        & other_next & (burned_area_recent == 1) & (peat == 1), 3112322, forest_state_array)   \n",
    "\n",
    "    ### Forestry\n",
    "    # Loss:no SDPT:non-SDPT forestry:no recent fire:no peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & non_sdpt_forestry & (burned_area_recent == 0) & (peat == 0), 31211, forest_state_array)   \n",
    "    #Loss:no SDPT:non-SDPT forestry:no recent fire:peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & non_sdpt_forestry & (burned_area_recent == 0) & (peat == 1), 31212, forest_state_array)   \n",
    "    #Loss:no SDPT:non-SDPT forestry:recent fire:no peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & non_sdpt_forestry & (burned_area_recent == 1) & (peat == 0), 31221, forest_state_array)   \n",
    "    #Loss:no SDPT:non-SDPT forestry:recent fire:peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & non_sdpt_forestry & (burned_area_recent == 1) & (peat == 1), 31222, forest_state_array)   \n",
    "    \n",
    "    ### Forestry\n",
    "    #Loss:SDPT:no recent fire:no peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest > 0) & (burned_area_recent == 0) & (peat == 0), 3211, forest_state_array)   \n",
    "    #Loss:SDPT:no recent fire:peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest > 0) & (burned_area_recent == 0) & (peat == 1), 3212, forest_state_array)   \n",
    "    #Loss:SDPT:recent fire:no peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest > 0) & (burned_area_recent == 1) & (peat == 0), 3221, forest_state_array)  \n",
    "    #Loss:SDPT:recent fire:peat\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest > 0) & (burned_area_recent == 1) & (peat == 1), 3222, forest_state_array)  \n",
    "\n",
    "    print(\"No forest\")\n",
    "    forest_state_array = dask.array.where(\n",
    "        no_forest, 4, forest_state_array)     #non-forest remaining non-forest \n",
    "    \n",
    "\n",
    "    print(\"At return statement\")\n",
    "    return forest_state_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning forest states\n",
      "Maintained branch\n",
      "Gain branch\n",
      "Loss branch\n",
      "No forest\n",
      "At return statement\n",
      "CPU times: total: 7.39 s\n",
      "Wall time: 4.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# xarray dataarray of 0s that has the properties of forest_height_current\n",
    "forest_state_zeros = xr.zeros_like(forest_height_current)\n",
    "\n",
    "# One compute() command for the entire function\n",
    "# per https://docs.dask.org/en/stable/best-practices.html#avoid-calling-compute-repeatedly\n",
    "forest_states = dask.compute(classify())   # returns a tuple with the first element a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the forest_state_zeros numpy array to a xarray dataarray\n",
    "state_da = xr.DataArray(forest_states[0], dims=('y', 'x'), coords={'x': forest_state_zeros['x'], 'y': forest_state_zeros['y']})\n",
    "\n",
    "# Exports dataarray to raster\n",
    "state_da.rio.set_crs(\"EPSG:4326\")\n",
    "state_da.rio.to_raster(f'{local_out_dir}forest_states_{current_year}__{timestr}_{tile_size}_deg.tif', compress='DEFLATE', dtype='uint32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summing values in multiple stacked data arrays within a dataset\n",
    "\n",
    "# https://stackoverflow.com/questions/65149355/is-there-a-faster-way-to-sum-xarray-dataset-variables\n",
    "vars_to_sum = [\"forest_height_2016\", \"forest_height_2017\", \"forest_height_2018\", \"forest_height_2019\", \"forest_height_2020\", \"forest_height_2021\"]\n",
    "\n",
    "summed_variables = forest_height_ds[vars_to_sum].to_array().sum(\"variable\").compute()\n",
    "summed_variables\n",
    "# summed_dataset = forest_height_ds.compute()\n",
    "# summed_dataset\n",
    "\n",
    "summed_variables.rio.to_raster(f'{local_out_dir}summed_heights_{current_year}__{timestr}_{tile_size}_deg.tif', compress='DEFLATE', dtype='uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_simple(dfs):\n",
    "    print(\"Assigning forest states\")    \n",
    "    forest_state_array = dask.array.where(\n",
    "        (dfs.forest_height_previous >= 5) & (dfs.forest_height_current >= 5), \n",
    "        1, forest_state_zeros)\n",
    "    forest_state_array = dask.array.where((\n",
    "        ((dfs.forest_height_previous >= 5) & (dfs.forest_height_current < 5)) \n",
    "         | (dfs.forest_loss_detection == 1)), \n",
    "        2, forest_state_array)\n",
    "    forest_state_array = dask.array.where(\n",
    "        (dfs.forest_height_previous < 5) & (dfs.forest_height_current >= 5), \n",
    "        3, forest_state_array)\n",
    "\n",
    "    return forest_state_array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
