{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30181827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# dask/parallelization libraries\n",
    "import coiled\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask.distributed import print as dask_print\n",
    "import dask.config\n",
    "import distributed\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import rasterio.transform\n",
    "import rasterio.windows\n",
    "from osgeo import gdal\n",
    "from subprocess import check_call\n",
    "\n",
    "from numba import jit\n",
    "import concurrent.futures\n",
    "\n",
    "import boto3\n",
    "import time\n",
    "import math\n",
    "import ctypes\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe44e76",
   "metadata": {},
   "source": [
    "<font size=\"6\">Making cloud and local clusters</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4591aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6953352de6b42e6a9035cf4be3af8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Package - bcrypt, bcrypt==4.1.0 has no install candidate for linux-64 on conda-forge\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Package - bcrypt, bcrypt==4.1.0 has no install candidate for linux-64 on conda-forge\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭────────────────────────────────────────── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Package Info</span> ──────────────────────────────────────────╮\n",
       "│                                  ╷                                                               │\n",
       "│  <span style=\"font-weight: bold\"> Package                        </span>│<span style=\"font-weight: bold\"> Note                                                        </span>  │\n",
       "│ ╶────────────────────────────────┼─────────────────────────────────────────────────────────────╴ │\n",
       "│   et-xmlfile                     │ https://pypi.org/pypi                                         │\n",
       "│                                  ╵                                                               │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭────────────────────────────────────────── \u001b[1;32mPackage Info\u001b[0m ──────────────────────────────────────────╮\n",
       "│                                  ╷                                                               │\n",
       "│  \u001b[1m \u001b[0m\u001b[1mPackage                       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mNote                                                       \u001b[0m\u001b[1m \u001b[0m  │\n",
       "│ ╶────────────────────────────────┼─────────────────────────────────────────────────────────────╴ │\n",
       "│   et-xmlfile                     │ https://pypi.org/pypi                                         │\n",
       "│                                  ╵                                                               │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────── <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Not Synced with Cluster</span> ─────────────────────────────────────╮\n",
       "│            ╷                                                                         ╷           │\n",
       "│  <span style=\"font-weight: bold\"> Package  </span>│<span style=\"font-weight: bold\"> Error                                                                   </span>│<span style=\"font-weight: bold\"> Risk    </span>  │\n",
       "│ ╶──────────┼─────────────────────────────────────────────────────────────────────────┼─────────╴ │\n",
       "│   bcrypt   │ bcrypt==4.1.0 has no install candidate for linux-64 on conda-forge      │ Warning   │\n",
       "│            ╵                                                                         ╵           │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────── \u001b[1;31mNot Synced with Cluster\u001b[0m ─────────────────────────────────────╮\n",
       "│            ╷                                                                         ╷           │\n",
       "│  \u001b[1m \u001b[0m\u001b[1mPackage \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mError                                                                  \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mRisk   \u001b[0m\u001b[1m \u001b[0m  │\n",
       "│ ╶──────────┼─────────────────────────────────────────────────────────────────────────┼─────────╴ │\n",
       "│   bcrypt   │ bcrypt==4.1.0 has no install candidate for linux-64 on conda-forge      │ Warning   │\n",
       "│            ╵                                                                         ╵           │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b876e2388fd44177be8643caba4871e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-391cd163-a4c6-11ee-8c0f-00155d3eb721</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> coiled.Cluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"https://cluster-zzgnt.dask.host/HyPFspCCSwcaWCWi/status\" target=\"_blank\">https://cluster-zzgnt.dask.host/HyPFspCCSwcaWCWi/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">Cluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">next_gen_forest_carbon_flux_model</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"https://cluster-zzgnt.dask.host/HyPFspCCSwcaWCWi/status\" target=\"_blank\">https://cluster-zzgnt.dask.host/HyPFspCCSwcaWCWi/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-cd6a26a7-376f-4d2e-a0ac-2bc569a097d7</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tls://10.0.57.28:8786\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://10.0.57.28:8787/status\" target=\"_blank\">http://10.0.57.28:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tls://10.0.57.28:8786' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test cluster\n",
    "coiled_cluster = coiled.Cluster(\n",
    "    n_workers=1,\n",
    "    use_best_zone=True, \n",
    "    compute_purchase_option=\"spot_with_fallback\",\n",
    "    idle_timeout=\"10 minutes\",\n",
    "    region=\"us-east-1\",\n",
    "    name=\"next_gen_forest_carbon_flux_model\", \n",
    "    account='jterry64', # Necessary to use the AWS environment that Justin set up in Coiled\n",
    "    worker_memory = \"32GiB\" \n",
    ")\n",
    "\n",
    "# Coiled cluster (cloud run)\n",
    "coiled_client = coiled_cluster.get_client()\n",
    "coiled_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a497a522-1db9-45a9-aca5-e99bb90acd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full cluster\n",
    "# Fewer workers with somewhat more memory. Even this configuration has workers entering the red zone and running out of memory but it seems to be okay\n",
    "coiled_cluster = coiled.Cluster(\n",
    "    n_workers=18,\n",
    "    use_best_zone=True, \n",
    "    compute_purchase_option=\"spot_with_fallback\",\n",
    "    idle_timeout=\"10 minutes\",\n",
    "    region=\"us-east-1\",\n",
    "    name=\"next_gen_forest_carbon_flux_model\", \n",
    "    account='jterry64', # Necessary to use the AWS environment that Justin set up in Coiled\n",
    "    worker_memory = \"205GiB\" \n",
    ")\n",
    "\n",
    "# Coiled cluster (cloud run)\n",
    "coiled_client = coiled_cluster.get_client()\n",
    "coiled_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f10ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coiled cluster (cloud run)\n",
    "coiled_client = coiled_cluster.get_client()\n",
    "coiled_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d54a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local single-process cluster (local run). Will run .compute() on just one process, not a whole cluster.\n",
    "local_client = Client(processes=False)\n",
    "local_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53da8ca-0c69-415f-a247-1dab6e7140f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_client = Client()\n",
    "local_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8387c-c700-4137-af80-cc75e689d8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local cluster with multiple workers\n",
    "local_cluster = LocalCluster()  \n",
    "local_client = Client(local_cluster)\n",
    "local_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768fe323",
   "metadata": {},
   "source": [
    "<font size=\"6\">Shutting down cloud and local clusters</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bfbe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "coiled_cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f376b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c44f117",
   "metadata": {},
   "source": [
    "<font size=\"6\">Analysis</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5ce237",
   "metadata": {},
   "source": [
    "<font size=\"4\">Paths and functions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6832ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General paths and constants\n",
    "\n",
    "input_uri = 's3://gfw2-data/forest_change/GLAD_Europe_height_data/202312_published/'\n",
    "output_suffix = 'processed/20231227/'\n",
    "\n",
    "def timestr():\n",
    "    return time.strftime(\"%Y%m%d_%H_%M_%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ee3796-717c-4b93-895d-2010d933a342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns list of all chunk boundaries within a bounding box for chunks of a given size\n",
    "def get_chunk_bounds(chunk_params):\n",
    "\n",
    "    min_x = chunk_params[0]\n",
    "    min_y = chunk_params[1]\n",
    "    max_x = chunk_params[2]\n",
    "    max_y = chunk_params[3]\n",
    "    chunk_size = chunk_params[4]\n",
    "    \n",
    "    x, y = (min_x, min_y)\n",
    "    chunks = []\n",
    "\n",
    "    # Polygon Size\n",
    "    while y < max_y:\n",
    "        while x < max_x:\n",
    "            bounds = [\n",
    "                x,\n",
    "                y,\n",
    "                x + chunk_size,\n",
    "                y + chunk_size,\n",
    "            ]\n",
    "            chunks.append(bounds)\n",
    "            x += chunk_size\n",
    "        x = min_x\n",
    "        y += chunk_size\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Returns the encompassing tile_id string in the form YYN/S_XXXE/W based on a coordinate\n",
    "def xy_to_tile_id(top_left_x, top_left_y):\n",
    "\n",
    "    lat_ceil = math.ceil(top_left_y/10.0) * 10\n",
    "    lng_floor = math.floor(top_left_x/10.0) * 10\n",
    "    \n",
    "    lng: str = f\"{str(lng_floor).zfill(3)}E\" if (lng_floor >= 0) else f\"{str(-lng_floor).zfill(3)}W\"\n",
    "    lat: str = f\"{str(lat_ceil).zfill(2)}N\" if (lat_ceil >= 0) else f\"{str(-lat_ceil).zfill(2)}S\"\n",
    "\n",
    "    return f\"{lat}_{lng}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a42ecf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazily opens tile within provided bounds (i.e. one chunk) and returns as a numpy array\n",
    "# If it can't open the chunk (no data in it), it returns an array of all 0s\n",
    "def get_tile_dataset_rio(uri, bounds, chunk_length):\n",
    "\n",
    "    try:\n",
    "        with rasterio.open(uri) as ds:\n",
    "            window = rasterio.windows.from_bounds(*bounds, ds.transform)\n",
    "            data = ds.read(1, window=window)\n",
    "    except:\n",
    "        data = np.zeros((chunk_length, chunk_length))\n",
    "\n",
    "    if data.size==0:\n",
    "        # dask_print(\"No data in chunk\")\n",
    "        return np.zeros((chunk_length, chunk_length))\n",
    "    else:\n",
    "        # dask_print(\"Data in chunk\")\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf4b896",
   "metadata": {},
   "source": [
    "<font size=\"4\">Model steps</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01f0ed26-f696-4a06-a2bd-7764b0c0ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuts Europe-size rasters to GLAD 10x10 tiles\n",
    "def translate_to_GLAD_tile(bounds, chunk_length_deg, year):\n",
    " \n",
    "    futures = {}\n",
    "    layers = {}\n",
    "\n",
    "    bounds_str = \"_\".join([str(round(x)) for x in bounds])\n",
    "    chunk_length_pixels = int(chunk_length_deg * (40000/10))\n",
    "\n",
    "    block_size = 400\n",
    "\n",
    "    # Submit requests to S3 for input chunks but don't actually download them yet. This queueing of the requests before downloading them speeds up the downloading\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        \n",
    "        tile_id = xy_to_tile_id(bounds[0], bounds[3])\n",
    "\n",
    "        tree_height_uri = f'{input_uri}tree_height/raw/Tree_height_{year}.tif'\n",
    "        tree_extent_uri = f'{input_uri}tree_extent/raw/Tree_extent_{year}.tif'\n",
    "        tree_removal_uri = f'{input_uri}tree_removal/raw/Tree_removal_{year}.tif'\n",
    "        \n",
    "        futures[executor.submit(get_tile_dataset_rio, tree_height_uri, bounds, chunk_length_pixels)] = f\"tree_height_{year}\"\n",
    "        # futures[executor.submit(get_tile_dataset_rio, tree_extent_uri, bounds, chunk_length_pixels)] = f\"tree_extent_{year}\"\n",
    "        # futures[executor.submit(get_tile_dataset_rio, tree_removal_uri, bounds, chunk_length_pixels)] = f\"tree_removal_{year}\"\n",
    "\n",
    "\n",
    "    # Wait for requests to come back with data from S3\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        layer = futures[future]\n",
    "        layers[layer] = future.result()\n",
    "\n",
    "    # Skips chunk if it has no forest extent in it\n",
    "    if not np.any(layers[f\"tree_height_{year}\"]):\n",
    "        dask_print(f\"No data in chunk {bounds_str} for {year}. Skipping: {timestr()}\")\n",
    "        return \n",
    "    \n",
    "    dask_print(f\"Data in chunk {bounds_str} for {year}. Proceeding: {timestr()}.\")\n",
    "\n",
    "    transform = rasterio.transform.from_bounds(*bounds, width=chunk_length_pixels, height=chunk_length_pixels)\n",
    "\n",
    "    # Output files to upload to s3\n",
    "    output_dict = {\n",
    "        \"tree_height\": [layers[f\"tree_height_{year}\"], f\"forest_change/GLAD_Europe_height_data/202312_published/tree_height/{output_suffix}\"],\n",
    "        # \"tree_extent\": [layers[f\"tree_extent_{year}\"], f\"forest_change/GLAD_Europe_height_data/202312_published/tree_extent/{output_suffix}\"],\n",
    "        # \"tree_removal\": [layers[f\"tree_removal_{year}\"], f\"forest_change/GLAD_Europe_height_data/202312_published/tree_removal/{output_suffix}\"]                          \n",
    "    }\n",
    "\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "\n",
    "    # For every output file, saves from array to local raster, then to s3.\n",
    "    # Can't save directly to s3, unfortunately, so need to save locally first.\n",
    "    for key, value in output_dict.items():\n",
    "\n",
    "        # If the originl raster doesn't go all the way to the edges of the chunk, the numpy array must be padded to achieve the desired dimensions\n",
    "        # Define the target dimensions\n",
    "        target_shape = (chunk_length_pixels, chunk_length_pixels)\n",
    "        \n",
    "        # Calculate the amount of padding needed for each dimension\n",
    "        pad_width = ((0, max(0, target_shape[0] - value[0].shape[0])),\n",
    "                     (0, max(0, target_shape[1] - value[0].shape[1])))\n",
    "        dask_print(\"Pad width:\", pad_width)\n",
    "            \n",
    "        # Pads the rows to 40,000 rows\n",
    "        # Special case for northeastern-most. Without this, the padding would be rows below the data and the data would be erronesously at the top of the tile.\n",
    "        if tile_id == \"80N_030E\":\n",
    "            dask_print(f\"Doing special 80N padding for {key} {bounds_str} in {tile_id} for {year}: {timestr()}\") \n",
    "            rows_to_pad = max(0, chunk_length_pixels - value[0].shape[0])\n",
    "            dask_print(\"Chunk length:\", chunk_length_pixels)\n",
    "            dask_print(\"Dimension 0 (rows):\", value[0].shape[0])\n",
    "            dask_print(\"Max of 0 and chunk_length - rows:\", max(0, chunk_length_pixels - value[0].shape[0]))\n",
    "            padding_above = np.zeros((rows_to_pad, chunk_length_pixels))\n",
    "            dask_print(\"Padding above:\", padding_above)\n",
    "            dask_print(\"Padding above shape:\", padding_above.shape)\n",
    "            dask_print(\"Input data before column padding:\", value[0])\n",
    "            dask_print(\"Input data before column padding shape:\", value[0].shape)\n",
    "\n",
    "\n",
    "            pad_width = ((0, max(0, value[0].shape[0] - value[0].shape[0])),\n",
    "                         (0, max(0, target_shape[1] - value[0].shape[1])))\n",
    "            dask_print(\"Pad width:\", pad_width)\n",
    "            \n",
    "            value[0] = np.pad(value[0], pad_width, mode='constant', constant_values=0)\n",
    "            dask_print(\"Input data after column padding:\", value[0])\n",
    "            dask_print(\"Input data after column padding shape:\", value[0].shape)\n",
    "            value[0] = np.concatenate((padding_above, value[0]), axis=0)\n",
    "            # value[0] = np.vstack((padding_above, value[0]))\n",
    "            dask_print(\"Input data after stacking shape:\", value[0].shape)\n",
    "        elif value[0].shape[0] < chunk_length_pixels:\n",
    "            dask_print(f\"Rows in {key} {bounds_str} in {tile_id} for {year} need padding: {timestr()}\")\n",
    "            value[0] = np.pad(value[0], pad_width, mode='constant', constant_values=0)\n",
    "        else:\n",
    "            dask_print(f\"Rows in {key} {bounds_str} in {tile_id} for {year} do not need padding: {timestr()}\")\n",
    "\n",
    "        # Pads the columns to 40,000 columns\n",
    "        if value[0].shape[1] < chunk_length_pixels:\n",
    "            dask_print(f\"Columns in {key} {bounds_str} in {tile_id} for {year} do need padding: {timestr()}\")\n",
    "            value[0] = np.pad(value[0], pad_width, mode='constant', constant_values=0)\n",
    "        else:\n",
    "            dask_print(f\"Columns in {key} {bounds_str} in {tile_id} for {year} do not need padding: {timestr()}\")\n",
    "        \n",
    "        file_name_intermediate = f'{tile_id}__{bounds_str}__{key}__{year}__{timestr()}_intermediate'\n",
    "        # file_name_final = f'{tile_id}__{bounds_str}__{key}__{year}__{timestr()}'  # for testing\n",
    "        file_name_final = f'{tile_id}_{key}__{year}'\n",
    "        upload_file = f\"{value[1]}{file_name_final}.tif\"\n",
    "\n",
    "        dask_print(f\"Saving {key} {bounds_str} in {tile_id} for {year} locally: {timestr()}\")\n",
    "\n",
    "        # This doesn't actually successfully create rasters with 400x400 windows. They were instead chunk_length_pixels x 400. \n",
    "        # Thus, I'm using rasterio to create an intermediate raster with partially correct dimensions, then correcting it with gdal_translate\n",
    "        with rasterio.open(f\"/tmp/{file_name_intermediate}.tif\", 'w', driver='GTiff', width=chunk_length_pixels, height=chunk_length_pixels, count=1, dtype='uint8', \n",
    "                           crs='EPSG:4326', transform=transform, compress='lzw', blockxsize=block_size, blockysize=block_size) as dst:\n",
    "            dst.write(value[0].astype(rasterio.uint8), 1)\n",
    "\n",
    "        input_path = f\"/tmp/{file_name_intermediate}.tif\"\n",
    "        output_path = f\"/tmp/{file_name_final}.tif\"\n",
    "        \n",
    "        input_dataset = gdal.Open(input_path)\n",
    "        \n",
    "        # Get information from the intermediate dataset\n",
    "        width = input_dataset.RasterXSize\n",
    "        height = input_dataset.RasterYSize\n",
    "        count = input_dataset.RasterCount\n",
    "        dtype = input_dataset.GetRasterBand(1).DataType\n",
    "        crs = input_dataset.GetProjection()\n",
    "        \n",
    "        # Set final output creation options, including block size\n",
    "        options = [\n",
    "            'TILED=YES',\n",
    "            f'BLOCKXSIZE={block_size}',\n",
    "            f'BLOCKYSIZE={block_size}',\n",
    "            'COMPRESS=LZW',\n",
    "        ]\n",
    "        \n",
    "        # Create the output dataset using gdal.Translate\n",
    "        gdal.Translate(\n",
    "            output_path,\n",
    "            input_path,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            format='GTiff',\n",
    "            outputType=dtype,\n",
    "            creationOptions=options,\n",
    "        )\n",
    "\n",
    "        dask_print(f\"Uploading {key} {bounds_str} in {tile_id} for {year} to s3: {timestr()}\")\n",
    "        s3_client.upload_file(f\"/tmp/{file_name_final}.tif\", \"gfw2-data\", Key=upload_file)\n",
    "\n",
    "        dask_print(f\"Cleaning up {key} {bounds_str} in {tile_id} for {year}: {timestr()}\")\n",
    "        \n",
    "        # Close the rasterio objects\n",
    "        input_dataset = None\n",
    "        output_dataset = None\n",
    "\n",
    "        # Delete the intermediate raster\n",
    "        os.remove(f\"/tmp/{file_name_intermediate}.tif\")\n",
    "\n",
    "        # Delete the numpy object\n",
    "        del value[0]\n",
    "\n",
    "\n",
    "    # TODO: add last year of loss creation\n",
    "    # tree_removal_latest_date_uri = f'{general_uri}202312_published/tree_removal_latest_date/raw/Tree_removal_latest_date.tif'\n",
    "    # futures[executor.submit(get_tile_dataset_rio, tree_removal_latest_date_uri, bounds, chunk_length_pixels)] = f\"tree_removal_latest_date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "157f4f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years to iterate through: [2021]\n",
      "Processing 1 tasks: 1 chunks by 1 years\n",
      "Data in chunk 30_70_40_80 for 2021. Proceeding: 20231227_15_25_44.\n",
      "Pad width: ((0, 31998), (0, 31998))\n",
      "Doing special 80N padding for tree_height 30_70_40_80 in 80N_030E for 2021: 20231227_15_25_44\n",
      "Chunk length: 40000\n",
      "Dimension 0 (rows): 8002\n",
      "Max of 0 and chunk_length - rows: 31998\n",
      "Padding above: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Padding above shape: (31998, 40000)\n",
      "Input data before column padding: [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Input data before column padding shape: (8002, 8002)\n",
      "Pad width: ((0, 0), (0, 31998))\n",
      "Input data after column padding: [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Input data after column padding shape: (8002, 40000)\n",
      "Input data after stacking shape: (40000, 40000)\n",
      "Columns in tree_height 30_70_40_80 in 80N_030E for 2021 do not need padding: 20231227_15_25_49\n",
      "Saving tree_height 30_70_40_80 in 80N_030E for 2021 locally: 20231227_15_25_49\n",
      "Uploading tree_height 30_70_40_80 in 80N_030E for 2021 to s3: 20231227_15_26_03\n",
      "Cleaning up tree_height 30_70_40_80 in 80N_030E for 2021: 20231227_15_26_03\n",
      "CPU times: user 178 ms, sys: 17.7 ms, total: 195 ms\n",
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Year to start the analysis\n",
    "# start_year = 2001   # all years\n",
    "# start_year = 2012  # last few years\n",
    "# start_year = 2020  # last two years\n",
    "start_year = 2021  # final year\n",
    "\n",
    "years = list(range(start_year, 2022))\n",
    "print(f\"Years to iterate through: {years}\")\n",
    "\n",
    "# Area to analyze\n",
    "# chunk_params arguments: W, S, E, N, chunk size (degrees)\n",
    "chunk_params = [-10, 30, 40, 80, 10]  # all of Europe (25 chunks)\n",
    "# chunk_params = [10, 40, 20, 50, 10]    # 10x10 deg (50N_010E, doesn't require any padding), 1 chunk\n",
    "# chunk_params = [10, 30, 20, 40, 10]    # 10x10 deg (40N_010E, requires row padding at bottom), 1 chunk\n",
    "# chunk_params = [20, 70, 30, 80, 10]    # 10x10 deg (80N_020E, requires row padding at top), 1 chunk\n",
    "chunk_params = [30, 70, 40, 80, 10]    # 10x10 deg (80N_030E, requires row padding at top and right (NE corner tile)), 1 chunk\n",
    "# chunk_params = [30, 60, 40, 70, 10]    # 10x10 deg (70N_030E, requires column padding), 1 chunk\n",
    "# chunk_params = [10, 46, 14, 50, 2]   # 4x4 deg, 4 chunks\n",
    "# chunk_params = [10, 48, 12, 50, 1]   # 2x2 deg, 4 chunks\n",
    "# chunk_params = [10, 49, 11, 50, 1]   # 1x1 deg, 1 chunk\n",
    "# chunk_params = [10, 49, 11, 50, 0.5] # 1x1 deg, 4 chunks\n",
    "# chunk_params = [10, 49.5, 10.5, 50, 0.25] # 0.5x0.5 deg, 4 chunks\n",
    "# chunk_params = [10, 49.5, 10.5, 50, 0.5] # 0.5x0.5 deg, 1 chunk\n",
    "# chunk_params = [10, 49.75, 10.25, 50, 0.25] # 0.25x0.25 deg, 1 chunk\n",
    "\n",
    "# Makes list of chunks to analyze\n",
    "chunks = get_chunk_bounds(chunk_params)  \n",
    "print(f\"Processing {len(chunks)*len(years)} tasks: {len(chunks)} chunks by {len(years)} years\")\n",
    "\n",
    "# Creates list of tasks to run (1 task = 1 chunk * 1 year combo).\n",
    "# I made each task a chunk x year combo because the years don't need to be done sequentially and it was taking too much memory\n",
    "# to download all the inputs upfront.\n",
    "# Since I wasn't downloading all the inputs upfront (instead downloading each year of data as I needed it), \n",
    "# I figured I might as well make the tasks into chunk x year combinations. \n",
    "delayed = [dask.delayed(translate_to_GLAD_tile)(chunk, chunk_params[4], year) for chunk in chunks for year in years]\n",
    "\n",
    "# Actually runs analysis\n",
    "results = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e990f4-7b8e-4eae-ad54-096dc1d2e914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c73679f-bf48-420f-b6c0-d82f62d2d490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1258c93-ed68-4ebd-ab36-ed12af5bc36e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab7caa0-c02d-4e33-926e-7c9c8b8cee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuts Europe-size rasters to GLAD 10x10 tiles\n",
    "# This does not work. It transfers data in the 80N tile to the top of the new tile, which is incorrect\n",
    "def warp_to_GLAD_tile(bounds, chunk_length_deg, year):\n",
    " \n",
    "    futures = {}\n",
    "    layers = {}\n",
    "\n",
    "    bounds_str = \"_\".join([str(round(x)) for x in bounds])\n",
    "    chunk_length_pixels = int(chunk_length_deg * (40000/10))\n",
    "\n",
    "    block_size = 400\n",
    "\n",
    "    # Submit requests to S3 for input chunks but don't actually download them yet. This queueing of the requests before downloading them speeds up the downloading\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        \n",
    "        tile_id = xy_to_tile_id(bounds[0], bounds[3])\n",
    "\n",
    "        tree_height_uri = f'{input_uri}tree_height/raw/Tree_height_{year}.tif'\n",
    "        tree_extent_uri = f'{input_uri}tree_extent/raw/Tree_extent_{year}.tif'\n",
    "        tree_removal_uri = f'{input_uri}tree_removal/raw/Tree_removal_{year}.tif'\n",
    "        \n",
    "        futures[executor.submit(get_tile_dataset_rio, tree_height_uri, bounds, chunk_length_pixels)] = f\"tree_height_{year}\"\n",
    "        # futures[executor.submit(get_tile_dataset_rio, tree_extent_uri, bounds, chunk_length_pixels)] = f\"tree_extent_{year}\"\n",
    "        # futures[executor.submit(get_tile_dataset_rio, tree_removal_uri, bounds, chunk_length_pixels)] = f\"tree_removal_{year}\"\n",
    "\n",
    "\n",
    "    # Wait for requests to come back with data from S3\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        layer = futures[future]\n",
    "        layers[layer] = future.result()\n",
    "\n",
    "    # Skips chunk if it has no forest extent in it\n",
    "    if not np.any(layers[f\"tree_height_{year}\"]):\n",
    "        dask_print(f\"No data in chunk {bounds_str} for {year}. Skipping: {timestr()}\")\n",
    "        return \n",
    "    \n",
    "    dask_print(f\"Data in chunk {bounds_str} for {year}. Proceeding: {timestr()}.\")\n",
    "\n",
    "    transform = rasterio.transform.from_bounds(*bounds, width=chunk_length_pixels, height=chunk_length_pixels)\n",
    "\n",
    "    # Output files to upload to s3\n",
    "    output_dict = {\n",
    "        \"tree_height\": [layers[f\"tree_height_{year}\"], f\"forest_change/GLAD_Europe_height_data/202312_published/tree_height/{output_suffix}\"],\n",
    "        # \"tree_extent\": [layers[f\"tree_extent_{year}\"], f\"forest_change/GLAD_Europe_height_data/202312_published/tree_extent/{output_suffix}\"],\n",
    "        # \"tree_removal\": [layers[f\"tree_removal_{year}\"], f\"forest_change/GLAD_Europe_height_data/202312_published/tree_removal/{output_suffix}\"]                          \n",
    "    }\n",
    "\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "\n",
    "    # For every output file, saves from array to local raster, then to s3.\n",
    "    # Can't save directly to s3, unfortunately, so need to save locally first.\n",
    "    for key, value in output_dict.items():\n",
    "\n",
    "        dask_print(f\"Saving {key} {bounds_str} in {tile_id} for {year} locally: {timestr()}\")\n",
    "\n",
    "        input_s3_path = \"/vsis3/gfw2-data/forest_change/GLAD_Europe_height_data/202312_published/tree_height/raw/Tree_height_2021.tif\"\n",
    "\n",
    "        out_tile = f'{tile_id}_{key}_{year}.tif'\n",
    "        output_path = f\"/tmp/{out_tile}\"\n",
    "        block_size = 400\n",
    "\n",
    "        cmd = ['gdalwarp', '-t_srs', 'EPSG:4326', '-co', 'COMPRESS=DEFLATE', \n",
    "               '-co', 'BLOCKXSIZE=400', '-co', 'BLOCKYSIZE=400',\n",
    "               # '-co', 'TILED=YES', '-co', 'BLOCKXSIZE=400', '-co', 'BLOCKYSIZE=400',\n",
    "               '-tr', str(0.00025), str(0.00025), '-tap', '-te',\n",
    "            str(bounds[0]), str(bounds[1]), str(bounds[2]), str(bounds[3]), '-dstnodata', '0', '-ot', 'byte', '-overwrite', input_s3_path, output_path]\n",
    "\n",
    "        check_call(cmd)\n",
    "\n",
    "        dask_print(f\"Uploading {key} {bounds_str} in {tile_id} for {year} to s3: {timestr()}\")\n",
    "        s3_client.upload_file(output_path, \"gfw2-data\", Key=f\"{value[1]}{out_tile}\")\n",
    "\n",
    "        dask_print(f\"Cleaning up {key} {bounds_str} in {tile_id} for {year}: {timestr()}\")\n",
    "        os.remove(output_path)\n",
    " \n",
    "\n",
    "\n",
    "    # TODO: add last year of loss creation\n",
    "    # tree_removal_latest_date_uri = f'{general_uri}202312_published/tree_removal_latest_date/raw/Tree_removal_latest_date.tif'\n",
    "    # futures[executor.submit(get_tile_dataset_rio, tree_removal_latest_date_uri, bounds, chunk_length_pixels)] = f\"tree_removal_latest_date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86975d0f-7f7c-45a9-81bc-c17eac8f5f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ca1fc-a554-4c39-92ae-8afbd5530dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afab2332-0f85-49e6-8141-69729d1840c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c084c04-a0fd-4c95-9188-e62bf14f9cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_id = '80N_020E'\n",
    "bounds = [20, 70, 30, 80]\n",
    "input_s3_path = \"/vsis3/gfw2-data/forest_change/GLAD_Europe_height_data/202312_published/tree_height/raw/Tree_height_2021.tif\"\n",
    "\n",
    "out_tile = '80N_020E_height_2021.tif'\n",
    "output_path = f\"/tmp/{out_tile}\"\n",
    "block_size = 400\n",
    "dask_print(bounds)\n",
    "\n",
    "cmd = ['gdalwarp', '-t_srs', 'EPSG:4326', '-co', 'COMPRESS=DEFLATE', '-tr', str(0.00025), str(0.00025), '-tap', '-te',\n",
    "    str(bounds[0]), str(bounds[1]), str(bounds[2]), str(bounds[3]), '-dstnodata', '0', '-ot', 'byte', '-overwrite', input_s3_path, output_path]\n",
    "\n",
    "check_call(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d12370-fe37-4d06-8a66-9210a4628988",
   "metadata": {},
   "outputs": [],
   "source": [
    "coiled_client.restart() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1114ac-9c2c-4cfb-9212-1d96f1aada06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run without dask at all\n",
    "process_chunk([10, 49, 11, 50], 1, start_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f5045c-a010-4762-88c3-a42a5d3edbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make 10x10 tiles:\n",
    "# gdalwarp from subprocess.check_call(cmd) isn't working\n",
    "# cmd = ['gdalwarp', '-tr', '0.00025', '0.00025', '-co', 'COMPRESS=DEFLATE', '-tap', '-te', str(10), str(49), str(11), str(50), '-dstnodata', '0', '-t_srs', 'EPSG:4326', \n",
    "#        '-overwrite', '-progress', '/vsis3/gfw2-data/forest_change/GLAD_Europe_height_data/202307_revision/FH_2021.tif', 'C:\\\\GIS\\\\Carbon_model_Europe\\\\outputs\\\\50N_010E_FH_2021.tif']\n",
    "# check_call(cmd)\n",
    "# gdalwarp -tr 0.00025 0.00025 -co COMPRESS=DEFLATE -tap -te 10 40 20 50 -dstnodata 0 -t_srs EPSG:4326 -overwrite /vsis3/gfw2-data/forest_change/GLAD_Europe_height_data/202307_revision/FH_2021.tif 50N_010E_FH_2021.tif\n",
    "# gdalwarp -tr 0.00025 0.00025 -co COMPRESS=DEFLATE -tap -te 10 40 20 50 -dstnodata 0 -t_srs EPSG:4326 -overwrite /vsis3/gfw2-data/forest_change/GLAD_Europe_height_data/202307_revision/FH_2020.tif 50N_010E_FH_2020.tif\n",
    "# gdalwarp -tr 0.00025 0.00025 -co COMPRESS=DEFLATE -tap -te 10 40 20 50 -dstnodata 0 -t_srs EPSG:4326 -overwrite /vsis3/gfw2-data/forest_change/GLAD_Europe_height_data/202307_revision/FH_2019.tif 50N_010E_FH_2019.tif\n",
    "# gdalwarp -tr 0.00025 0.00025 -co COMPRESS=DEFLATE -tap -te 10 40 20 50 -dstnodata 0 -t_srs EPSG:4326 -overwrite /vsis3/gfw2-data/forest_change/GLAD_Europe_height_data/202307_revision/FH_2018.tif 50N_010E_1FH_2018.tif\n",
    "# gdalwarp -tr 0.00025 0.00025 -co COMPRESS=DEFLATE -tap -te 10 40 20 50 -dstnodata 0 -t_srs EPSG:4326 -overwrite /vsis3/gfw2-data/forest_change/GLAD_Europe_height_data/202307_revision/DFL_2021.tif 50N_010E_DFL_2021.tif\n",
    "# gdalwarp -tr 0.00025 0.00025 -co COMPRESS=DEFLATE -tap -te 10 40 20 50 -dstnodata 0 -t_srs EPSG:4326 -overwrite /vsis3/gfw2-data/forest_change/GLAD_Europe_height_data/202307_revision/DFL_2020.tif 50N_010E_DFL_2020.tif\n",
    "# gdalwarp -tr 0.00025 0.00025 -co COMPRESS=DEFLATE -tap -te 10 40 20 50 -dstnodata 0 -t_srs EPSG:4326 -overwrite /vsis3/gfw2-data/forest_change/GLAD_Europe_height_data/202307_revision/DFL_2019.tif 50N_010E_DFL_2019.tif\n",
    "# gdalwarp -tr 0.00025 0.00025 -co COMPRESS=DEFLATE -tap -te 10 40 20 50 -dstnodata 0 -t_srs EPSG:4326 -overwrite /vsis3/gfw2-data/forest_change/GLAD_Europe_height_data/202307_revision/DFL_2018.tif 50N_010E_DFL_2018.tif\n",
    "# gdalwarp -tr 0.00025 0.00025 -co COMPRESS=DEFLATE -tap -te 10 40 20 50 -dstnodata 0 -t_srs EPSG:4326 -overwrite /vsis3/gfw2-data/climate/carbon_model/other_emissions_inputs/tree_cover_loss_drivers/processed/drivers_2022/20230407/50N_010E_tree_cover_loss_driver_processed.tif 50N_010E_1deg_tree_cover_loss_driver_processed.tif\n",
    "# gdalwarp -tr 0.00025 0.00025 -co COMPRESS=DEFLATE -tap -te 10 40 20 50 -dstnodata 0 -t_srs EPSG:4326 -overwrite /vsis3/gfw2-data/climate/carbon_model/other_emissions_inputs/tree_cover_loss_fires/20230315/processed/50N_010E_tree_cover_loss_fire_processed.tif 50N_010E_1deg_tree_cover_loss_fire_processed.tif\n",
    "# gdalwarp -tr 0.00025 0.00025 -co COMPRESS=DEFLATE -tap -te 10 40 20 50 -dstnodata 0 -t_srs EPSG:4326 -overwrite /vsis3/gfw2-data/climate/carbon_model/other_emissions_inputs/peatlands/processed/20230315/50N_010E_peat_mask_processed.tif 50N_010E_1deg_peat_mask_processed.tif\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
