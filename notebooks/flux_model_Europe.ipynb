{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from osgeo import gdal      # Necessary to do this import to get rasterio to import\n",
    "import rasterio as rio\n",
    "\n",
    "import time\n",
    "\n",
    "import math\n",
    "from enum import Enum\n",
    "from functools import reduce\n",
    "\n",
    "# dask/parallelization libraries\n",
    "import coiled\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster, futures_of\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "\n",
    "import botocore\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Making cloud and local clusters</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f695237801d43d4a4f3d600c102c41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭────────────────────────────────────────── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Package Info</span> ──────────────────────────────────────────╮\n",
       "│                                ╷                                                                 │\n",
       "│  <span style=\"font-weight: bold\"> Package                      </span>│<span style=\"font-weight: bold\"> Note                                                          </span>  │\n",
       "│ ╶──────────────────────────────┼───────────────────────────────────────────────────────────────╴ │\n",
       "│   coiled_local_carbon_notebook │ Source wheel built from                                         │\n",
       "│                                │ C:\\Users\\david.gibbs\\AppData\\Local\\anaconda3\\envs\\carbon_note   │\n",
       "│                                │ book                                                            │\n",
       "│                                ╵                                                                 │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭────────────────────────────────────────── \u001b[1;32mPackage Info\u001b[0m ──────────────────────────────────────────╮\n",
       "│                                ╷                                                                 │\n",
       "│  \u001b[1m \u001b[0m\u001b[1mPackage                     \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mNote                                                         \u001b[0m\u001b[1m \u001b[0m  │\n",
       "│ ╶──────────────────────────────┼───────────────────────────────────────────────────────────────╴ │\n",
       "│   coiled_local_carbon_notebook │ Source wheel built from                                         │\n",
       "│                                │ C:\\Users\\david.gibbs\\AppData\\Local\\anaconda3\\envs\\carbon_note   │\n",
       "│                                │ book                                                            │\n",
       "│                                ╵                                                                 │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24dad5996e8d4fe0b2a5bb4100dbe7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coiled_cluster = coiled.Cluster(\n",
    "    n_workers=10,\n",
    "    use_best_zone=True, \n",
    "    compute_purchase_option=\"spot_with_fallback\",\n",
    "    idle_timeout=\"20 minutes\",\n",
    "    # name=\"DGibbs Europe height flux model\", \n",
    "    account='jterry64'   # Necessary to use the AWS environment that Justin set up in Coiled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-97a9cc35-6dc5-11ee-b8ec-cc483a9e56d0</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> coiled.Cluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"https://cluster-rpvai.dask.host/wfyjjX29NPS3PkA6/status\" target=\"_blank\">https://cluster-rpvai.dask.host/wfyjjX29NPS3PkA6/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">Cluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">jterry64-a53dbebf-6</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"https://cluster-rpvai.dask.host/wfyjjX29NPS3PkA6/status\" target=\"_blank\">https://cluster-rpvai.dask.host/wfyjjX29NPS3PkA6/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 2\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 8\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 29.63 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-381d59f8-3fbb-4ef3-84b8-64baec844f99</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tls://10.1.18.242:8786\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 1\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://10.1.18.242:8787/status\" target=\"_blank\">http://10.1.18.242:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 4\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 14.81 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: jterry64-a53dbebf-6-worker-571fe520ef</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tls://10.1.23.212:42315\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 4\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://10.1.23.212:8787/status\" target=\"_blank\">http://10.1.23.212:8787/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 14.81 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tls://10.1.23.212:45693\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /scratch/dask-scratch-space/worker-l19w39nk\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tls://10.1.18.242:8786' processes=1 threads=4, memory=14.81 GiB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coiled cluster (cloud run)\n",
    "coiled_client = coiled_cluster.get_client()\n",
    "coiled_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the number of workers in the cluster\n",
    "new_workers = 8\n",
    "coiled_cluster.scale(new_workers)\n",
    "coiled_cluster.wait_for_workers(new_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local cluster (local run). Doesn't work-- .compute() method kill workers for unknown reasons. Can't use for now.\n",
    "# local_cluster = LocalCluster(silence_logs=False)\n",
    "local_cluster = LocalCluster()\n",
    "local_client = Client(local_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Local single-process cluster (local run). Will run .compute() on just one process, not a whole cluster.\n",
    "# local_client = Client(processes=False)\n",
    "# local_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Shutting down cloud and local clusters</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coiled_cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Analysis</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Paths and functions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General paths and constants\n",
    "\n",
    "general_uri = 's3://gfw2-data/forest_change/GLAD_Europe_height_data/'\n",
    "\n",
    "random_data_uri = 's3://gfw2-data/forest_change/GLAD_Europe_height_data/dummy_random_data__20230901/'\n",
    "\n",
    "local_out_dir = 'C:\\\\GIS\\\\Carbon_model_Europe\\\\outputs\\\\'\n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d\")\n",
    "\n",
    "height_cutoff = 5    # meters\n",
    "\n",
    "chunk_length = 2000   # Dimensions in pixels of dask chunks (width and height)\n",
    "\n",
    "tile_size = 2      # Tile size in degrees is from the top left of the tile. 10 is a full tile. Anything smaller is a subset of that.\n",
    "\n",
    "current_year = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads tile\n",
    "# From https://notebooks-staging.wri.org/user/dagibbs22/lab/tree/msims/biodiversity_global_stats.ipynb\n",
    "# Bounding box use comes from https://github.com/corteva/rioxarray/issues/115#issuecomment-1206673437 and https://corteva.github.io/rioxarray/html/examples/clip_box.html. \n",
    "\n",
    "# Tile size is from the top left of the tile\n",
    "def get_tile_dataset(uri, name, template=None, tile_size=10):\n",
    "    # If the input tile_size is too large, it reverts to 10 (standard tile size)\n",
    "    if tile_size > 10:\n",
    "        tile_size = 10\n",
    "    try:\n",
    "        raster = rioxarray.open_rasterio(uri, chunks=chunk_length, default_name=name, lock=False)\n",
    "        raster_extent = raster.rio.bounds()\n",
    "        minx=raster_extent[0]\n",
    "        miny=raster_extent[1]\n",
    "        maxx=raster_extent[2]\n",
    "        maxy=raster_extent[3]\n",
    "        return raster.rio.clip_box(minx=minx, miny=maxy-tile_size, maxx=minx+tile_size, maxy=maxy).squeeze(\"band\")\n",
    "    except rasterio.errors.RasterioIOError as e:\n",
    "        if template is not None:\n",
    "            return xr.zeros_like(template)\n",
    "        else:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context(Enum):\n",
    "    FOREST_MAINTAINED = 'FOREST MAINTAINED'\n",
    "    FOREST_GAIN = 'FOREST GAIN'\n",
    "    FOREST_LOSS = 'FOREST LOSS'\n",
    "    NON_PLANTED = 'NON PLANTED'\n",
    "    PLANTED = 'PLANTED'\n",
    "    NO_RECENT_FIRE = 'NO RECENT FIRE'\n",
    "    RECENT_FIRE = 'RECENT FIRE'\n",
    "    NO_PEAT = 'NO PEAT'\n",
    "    PEAT = 'PEAT'\n",
    "    LEAF = 'LEAF'\n",
    "\n",
    "def flatten_tuple(tup):\n",
    "    \"\"\"\n",
    "    Recursively flatten a nested tuple.\n",
    "    \"\"\"\n",
    "    flat_list = []\n",
    "\n",
    "    for item in tup:\n",
    "        if isinstance(item, tuple):\n",
    "            flat_list.extend(flatten_tuple(item))\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "\n",
    "    return tuple(flat_list)\n",
    "\n",
    "\n",
    "class CarbonBudgetClassifier():\n",
    "  def __init__(self, forest_maintained=None, forest_gain=None, forest_loss=None):\n",
    "    self.forest_maintained = forest_maintained\n",
    "    self.forest_gain = forest_gain\n",
    "    self.forest_loss = forest_loss\n",
    "    \n",
    "  def classify(self, forest_data):\n",
    "    if (not self.forest_maintained and not self.forest_gain and not self.forest_loss):\n",
    "        return ()\n",
    "    return flatten_tuple((\n",
    "        tuple(Classification(predicate=((forest_data['forest_height_previous'] >= height_cutoff) & \n",
    "                                (forest_data['forest_height_current'] >= height_cutoff)), \n",
    "                     context=Context.FOREST_MAINTAINED, val='1') + x for x in self.forest_maintained.classify(forest_data)),\n",
    "        tuple(Classification(predicate=((forest_data['forest_height_previous'] < height_cutoff) & \n",
    "                                (forest_data['forest_height_current'] >= height_cutoff)), \n",
    "                             context=Context.FOREST_GAIN, val='2') + x for x in self.forest_gain.classify(forest_data)),\n",
    "        tuple(Classification(predicate=((((forest_data['forest_height_previous'] >= height_cutoff) & \n",
    "                                 (forest_data['forest_height_current'] < height_cutoff)) \n",
    "                                | (forest_data['forest_loss_detection'] == 1))),\n",
    "                             context=Context.FOREST_LOSS, val='3') + x for x in self.forest_loss.classify(forest_data)),\n",
    "      ))\n",
    "\n",
    "\n",
    "class PlantedForestNode():\n",
    "  def __init__(self, non_planted=None, planted=None):\n",
    "    self.non_planted = non_planted\n",
    "    self.planted = planted\n",
    "\n",
    "  def classify(self, forest_data=None):\n",
    "    if (not self.non_planted and not self.planted):\n",
    "        return ()\n",
    "    return flatten_tuple((\n",
    "        tuple(Classification(predicate=(forest_data['planted_forest'] == 0), context=Context.NON_PLANTED, val='1') + x for x in self.non_planted.classify(forest_data)),\n",
    "        tuple(Classification(predicate=(forest_data['planted_forest'] > 0), context=Context.PLANTED, val='2') + x for x in self.planted.classify(forest_data)),\n",
    "      ))\n",
    "\n",
    "class RecentFireNode():\n",
    "  def __init__(self, no_recent_fire=None, recent_fire=None):\n",
    "    self.no_recent_fire = no_recent_fire\n",
    "    self.recent_fire = recent_fire\n",
    "\n",
    "  def classify(self, forest_data=None):\n",
    "    if (not self.no_recent_fire and not self.recent_fire):\n",
    "        return ()\n",
    "    return flatten_tuple((\n",
    "        tuple(Classification(predicate=(forest_data['burned_area_recent'] == 0), context=Context.NO_RECENT_FIRE, val='1') + x for x in self.no_recent_fire.classify(forest_data)),\n",
    "        tuple(Classification(predicate=(forest_data['burned_area_recent'] > 0), context=Context.RECENT_FIRE, val='2') + x for x in self.recent_fire.classify(forest_data)),\n",
    "    ))\n",
    "\n",
    "class PeatNode():\n",
    "  def __init__(self, no_peat=None, peat=None):\n",
    "    self.no_peat = no_peat\n",
    "    self.peat = peat\n",
    "\n",
    "  def classify(self, forest_data=None):\n",
    "    if (not self.no_peat and not self.no_peat):\n",
    "        return ()\n",
    "    return flatten_tuple((\n",
    "        tuple(Classification(predicate=(forest_data['peat'] == 0), context=Context.NO_PEAT, val='1') + x for x in self.no_peat.classify(forest_data)),\n",
    "        tuple(Classification(predicate=(forest_data['peat'] > 0), context=Context.PEAT, val='2') + x for x in self.peat.classify(forest_data)),\n",
    "    ))\n",
    "\n",
    "\n",
    "class Leaf():\n",
    "\n",
    "    def __init__(self, emission_factor=0.0):\n",
    "        self._emission_factor = float(emission_factor)\n",
    "\n",
    "    @property\n",
    "    def emission_factor(self):\n",
    "        return self._emission_factor\n",
    "\n",
    "    def classify(self, forest_data=None):\n",
    "        return (Classification(predicate=None,\n",
    "                               context=Context.LEAF,\n",
    "                               val='',\n",
    "                               emission_factor=self.emission_factor), )\n",
    "\n",
    "\n",
    "class Classification():\n",
    "\n",
    "    def __init__(self, predicate=None, context=(), val='', emission_factor=0.0):\n",
    "        self._predicate = predicate\n",
    "        self._context = context\n",
    "        self._val = val\n",
    "        self._emission_factor = emission_factor\n",
    "\n",
    "    @property\n",
    "    def predicate(self):\n",
    "        return self._predicate\n",
    "\n",
    "    @property\n",
    "    def context(self):\n",
    "        return self._context\n",
    "\n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val\n",
    "\n",
    "    @property\n",
    "    def emission_factor(self):\n",
    "        return self._emission_factor\n",
    "\n",
    "    def __add__(self, other):\n",
    "        if (other is None):\n",
    "            return self\n",
    "        if (isinstance(other, Classification)):\n",
    "            return Classification(\n",
    "                predicate=self.predicate if (other.predicate is None) else\n",
    "                (self.predicate & other.predicate),\n",
    "                context=flatten_tuple((self.context, ) + (other.context, )),\n",
    "                val=self.val + other.val,\n",
    "                emission_factor=other.emission_factor,\n",
    "            )\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Classification):\n",
    "            return (self.predicate == other.predicate\n",
    "                and self.context == other.context and self.val == other.val\n",
    "                and math.isclose(\n",
    "                    self.emission_factor, other.emission_factor, rel_tol=1e-9))\n",
    "        return False\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"\"\"\n",
    "        Classification:\n",
    "        predicate: {self.predicate}\n",
    "        context: {self.context}\n",
    "        val: {self.val}\n",
    "        emission_factor: {self.emission_factor}\n",
    "        \"\"\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Classification(predicate={self.predicate}, context={self.context}, val={self.val}, emission_factor={self.emission_factor})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Reading in data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://gfw2-data/forest_change/GLAD_Europe_height_data/202307_revision/test_10x10_deg/50N_010E_FH_2020.tif\n",
      "s3://gfw2-data/climate/carbon_model/other_emissions_inputs/burn_year/burn_year_10x10_clip/ba_2019_50N_010E.tif\n",
      "s3://gfw2-data/climate/carbon_model/other_emissions_inputs/burn_year/burn_year_10x10_clip/ba_2020_50N_010E.tif\n"
     ]
    }
   ],
   "source": [
    "# Input file locations\n",
    "\n",
    "# forest_height_previous_uri = f'{general_uri}202307_revision/FH_2020.tif'\n",
    "# forest_height_current_uri = f'{general_uri}202307_revision/FH_2021.tif'\n",
    "# forest_loss_detection_uri = f'{general_uri}202307_revision/DFL_2021.tif'\n",
    "\n",
    "forest_height_2016_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_FH_2016.tif'\n",
    "forest_height_2017_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_FH_2017.tif'\n",
    "forest_height_2018_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_FH_2018.tif'\n",
    "forest_height_2019_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_FH_2019.tif'\n",
    "forest_height_2020_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_FH_2020.tif'\n",
    "forest_height_2021_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_FH_2021.tif'\n",
    "\n",
    "# Using 10x10 degree rasters of actual data\n",
    "forest_height_previous_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_FH_{current_year-1}.tif'\n",
    "forest_height_current_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_FH_{current_year}.tif'\n",
    "forest_loss_detection_uri = f'{general_uri}202307_revision/test_10x10_deg/50N_010E_DFL_{current_year}.tif'\n",
    "\n",
    "driver_uri = \"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/tree_cover_loss_drivers/processed/drivers_2022/20230407/50N_010E_tree_cover_loss_driver_processed.tif\"\n",
    "planted_forest_type_uri = \"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/planted_forest_type/SDPT_v1/standard/20200730/50N_010E_plantation_type_oilpalm_woodfiber_other_unmasked.tif\"\n",
    "peat_uri = \"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/peatlands/processed/20230315/50N_010E_peat_mask_processed.tif\"\n",
    "\n",
    "landcover_composite_2000_uri = \"s3://gfw2-data/landcover/composite/2000/50N_010E_composite_landcover_2000.tif\"\n",
    "landcover_composite_2005_uri = \"s3://gfw2-data/landcover/composite/2005/50N_010E_composite_landcover_2005.tif\"\n",
    "landcover_composite_2010_uri = \"s3://gfw2-data/landcover/composite/2010/50N_010E_composite_landcover_2010.tif\"\n",
    "landcover_composite_2015_uri = \"s3://gfw2-data/landcover/composite/2015/50N_010E_composite_landcover_2015.tif\"\n",
    "landcover_composite_2020_uri = \"s3://gfw2-data/landcover/composite/2020/50N_010E_composite_landcover_2020.tif\"\n",
    "\n",
    "cropland_NE_2003_uri = \"s3://gfw2-data/landcover/cropland/2003/raw/Global_cropland_NE_2003.tif\"\n",
    "cropland_NE_2007_uri = \"s3://gfw2-data/landcover/cropland/2007/raw/Global_cropland_NE_2007.tif\"\n",
    "cropland_NE_2011_uri = \"s3://gfw2-data/landcover/cropland/2011/raw/Global_cropland_NE_2011.tif\"\n",
    "cropland_NE_2015_uri = \"s3://gfw2-data/landcover/cropland/2015/raw/Global_cropland_NE_2015.tif\"\n",
    "cropland_NE_2019_uri = \"s3://gfw2-data/landcover/cropland/2019/raw/Global_cropland_NE_2019.tif\"\n",
    "\n",
    "ba_two_before_uri = f's3://gfw2-data/climate/carbon_model/other_emissions_inputs/burn_year/burn_year_10x10_clip/ba_{current_year-2}_50N_010E.tif'\n",
    "ba_one_before_uri = f's3://gfw2-data/climate/carbon_model/other_emissions_inputs/burn_year/burn_year_10x10_clip/ba_{current_year-1}_50N_010E.tif'\n",
    "\n",
    "agb_2000_uri = \"s3://gfw2-data/climate/WHRC_biomass/WHRC_V4/Processed/50N_010E_t_aboveground_biomass_ha_2000.tif\"\n",
    "\n",
    "# # Using random data\n",
    "# forest_height_previous_uri = f'{random_data_uri}50N_010E_FH_2020_random_data.tif'\n",
    "# forest_height_current_uri = f'{random_data_uri}50N_010E_FH_2021_random_data.tif'\n",
    "# forest_loss_detection_uri = f'{random_data_uri}50N_010E_DFL_2021_random_data.tif'\n",
    "\n",
    "# driver_uri = f'{random_data_uri}50N_010E_tree_cover_loss_driver_processed_random_data.tif'\n",
    "# planted_forest_type_uri = f'{random_data_uri}50N_010E_plantation_type_oilpalm_woodfiber_other_unmasked_random_data.tif'\n",
    "# peat_uri = f'{random_data_uri}50N_010E_peat_mask_processed_random_data.tif'\n",
    "\n",
    "# ba_2017_uri = f'{random_data_uri}50N_010E_burned_area_2017_random_data.tif'\n",
    "# ba_2018_uri = f'{random_data_uri}50N_010E_burned_area_2018_random_data.tif'\n",
    "# ba_2019_uri = f'{random_data_uri}50N_010E_burned_area_2019_random_data.tif'\n",
    "# ba_2020_uri = f'{random_data_uri}50N_010E_burned_area_2020_random_data.tif'\n",
    "# ba_2021_uri = f'{random_data_uri}50N_010E_burned_area_2021_random_data.tif'\n",
    "\n",
    "print(forest_height_previous_uri)\n",
    "print(ba_two_before_uri)\n",
    "print(ba_one_before_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.39 s\n",
      "Wall time: 6.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Reads input files\n",
    "\n",
    "forest_height_2016 = get_tile_dataset(forest_height_2016_uri, name=\"forest_height_2016\", tile_size=tile_size)\n",
    "forest_height_2017 = get_tile_dataset(forest_height_2017_uri, name=\"forest_height_2017\", tile_size=tile_size)\n",
    "forest_height_2018 = get_tile_dataset(forest_height_2018_uri, name=\"forest_height_2018\", tile_size=tile_size)\n",
    "forest_height_2019 = get_tile_dataset(forest_height_2019_uri, name=\"forest_height_2019\", tile_size=tile_size)\n",
    "forest_height_2020 = get_tile_dataset(forest_height_2020_uri, name=\"forest_height_2020\", tile_size=tile_size)\n",
    "forest_height_2021 = get_tile_dataset(forest_height_2021_uri, name=\"forest_height_2021\", tile_size=tile_size)\n",
    "\n",
    "forest_height_previous = get_tile_dataset(forest_height_previous_uri, name=\"forest_height_previous\", tile_size=tile_size)\n",
    "forest_height_current = get_tile_dataset(forest_height_current_uri, name=\"forest_height_current\", tile_size=tile_size)\n",
    "forest_loss_detection = get_tile_dataset(forest_loss_detection_uri, name=\"forest_loss_detection\", tile_size=tile_size)\n",
    "\n",
    "driver = get_tile_dataset(driver_uri, name=\"driver\", tile_size=tile_size)\n",
    "planted_forest = get_tile_dataset(planted_forest_type_uri, name=\"planted_forest\", tile_size=tile_size)\n",
    "peat = get_tile_dataset(peat_uri, name=\"peat\", tile_size=tile_size)\n",
    "\n",
    "LC_previous = get_tile_dataset(landcover_composite_2015_uri, name=\"LC_previous\", tile_size=tile_size)\n",
    "LC_next = get_tile_dataset(landcover_composite_2020_uri, name=\"LC_next\", tile_size=tile_size)\n",
    "\n",
    "cropland_previous = get_tile_dataset(cropland_NE_2019_uri, name=\"cropland_previous\", tile_size=tile_size)\n",
    "\n",
    "ba_two_before = get_tile_dataset(ba_two_before_uri, name=\"ba_two_before\", tile_size=tile_size)\n",
    "ba_one_before = get_tile_dataset(ba_two_before_uri, name=\"ba_one_before\", tile_size=tile_size)\n",
    "\n",
    "agb_2000 = get_tile_dataset(agb_2000_uri, name=\"agb_2000\", tile_size=tile_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Recent burned area</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps raster of burned area in two preceding years\n",
    "def recent_burned_area(burned_area_recent_blank):\n",
    "\n",
    "    print(\"Mapping burned area in two preceding years: \", time.strftime(\"%Y%m%d-%H-%M-%S\")) \n",
    "    burned_area_recent_array = xr.where(((ba_two_before != 0) | (ba_one_before != 0)), 1, burned_area_recent_blank)\n",
    "\n",
    "    burned_area_recent_da = xr.DataArray(burned_area_recent_array, dims=('y', 'x'), coords={'x': burned_area_recent_blank['x'], 'y': burned_area_recent_blank['y']})\n",
    "    burned_area_recent_da.rio.set_crs(\"EPSG:4326\")\n",
    "\n",
    "    file_name = f'burned_area_recent_{current_year}__{timestr}_{tile_size}_deg'\n",
    "    burned_area_recent_da.rio.to_raster(f\"/tmp/{file_name}.tif\", compress='DEFLATE', dtype='uint8')\n",
    "\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    s3_client.upload_file(f\"/tmp/{file_name}.tif\", \"gfw2-data\", Key=f\"climate/forest_states/{file_name}.tif\")\n",
    "    \n",
    "    return burned_area_recent_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping burned area in two preceding years:  20231018-11-14-54\n",
      "CPU times: total: 4.38 s\n",
      "Wall time: 19.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# xarray dataarray of 0s that has the properties of forest_height_current\n",
    "burned_area_recent_blank = xr.zeros_like(forest_height_current)\n",
    "\n",
    "burned_area_recent = dask.persist(recent_burned_area(burned_area_recent_blank))\n",
    "# burned_area_recent\n",
    "\n",
    "# burned_area_recent = dask.persist(recent_burned_area(burned_area_recent_blank))\n",
    "# burned_area_recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'burned_area_recent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m futures_of(\u001b[43mburned_area_recent\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'burned_area_recent' is not defined"
     ]
    }
   ],
   "source": [
    "futures_of(burned_area_recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "coiled_client.restart()   # https://distributed.dask.org/en/latest/memory.html\n",
    "del burned_area_recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Maps raster of burned area in two preceding years\n",
    "\n",
    "# xarray dataarray of 0s that has the properties of forest_height_current\n",
    "burned_area_recent_blank = xr.zeros_like(forest_height_current)\n",
    "\n",
    "print(\"Mapping burned area in two preceding years\")\n",
    "burned_area_recent_array = dask.array.where(np.logical_or(ba_two_before != 0, ba_one_before != 0), 1, burned_area_recent_blank).compute()\n",
    "\n",
    "# Converts the burned_area_recent numpy array to a xarray dataarray\n",
    "burned_area_recent = xr.DataArray(burned_area_recent_array, dims=('y', 'x'), \n",
    "                                  coords={'x': burned_area_recent_blank['x'], 'y': burned_area_recent_blank['y']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Exports dataarray to raster\n",
    "burned_area_recent[0].rio.set_crs(\"EPSG:4326\")\n",
    "burned_area_recent[0].rio.to_raster(f'{local_out_dir}burned_area_recent_{current_year}__{timestr}_{tile_size}_deg.tif', compress='DEFLATE', dtype='uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Final year of forest</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines all the dataarrays into a dataset\n",
    "\n",
    "forest_height_ds = xr.Dataset({\n",
    "    # \"forest_height_2016\": forest_height_2016, \n",
    "    # \"forest_height_2017\": forest_height_2017, \n",
    "    # \"forest_height_2018\": forest_height_2018, \n",
    "    \"forest_height_2019\": forest_height_2019,\n",
    "    \"forest_height_2020\": forest_height_2020, \n",
    "    \"forest_height_2021\": forest_height_2021, \n",
    "})\n",
    "\n",
    "# forest_height_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Maps forest presence (>=5 m) for each year (each dataarray)\n",
    "\n",
    "def map_forests(data_array, dataset):\n",
    "    \n",
    "    year = data_array.name[-4:]\n",
    "    print(f\"Mapping forest presence for {year}\") \n",
    " \n",
    "    # xarray dataarray of 0s that has the properties of input dataarray\n",
    "    forest_presence_zeros = xr.zeros_like(data_array)\n",
    "\n",
    "    # Masks pixels with height >= 5 m\n",
    "    print(\"Masking pixels to >5 m: \", time.strftime(\"%Y%m%d-%H-%M-%S\"))\n",
    "    forest_presence = xr.where((data_array >= height_cutoff), int(year), forest_presence_zeros).persist()\n",
    "\n",
    "    # Converts numpy array to xarray dataarrayL\n",
    "    print(\"Converting numpy array to datarra: \", time.strftime(\"%Y%m%d-%H-%M-%S\"))\n",
    "    forest_presence_da = xr.DataArray(forest_presence, dims=('y', 'x'), coords={'x': data_array['x'], 'y': data_array['y']})\n",
    "    \n",
    "    # # Exports dataarray to raster\n",
    "    # print(\"Exporting to raster: \", time.strftime(\"%Y%m%d-%H-%M-%S\"))\n",
    "    # forest_presence_da.rio.set_crs(\"EPSG:4326\")\n",
    "    # forest_presence_da.rio.to_raster(f'{local_out_dir}forest_presence_{year}__{timestr}_{tile_size}_deg.tif', compress='DEFLATE', dtype='uint16')\n",
    "\n",
    "    return forest_presence_da\n",
    "\n",
    "# Applies the map_forests function to every dataarray in the dataset\n",
    "forest_presence_ds = forest_height_ds.map(map_forests, dataset=forest_height_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renames the forest presence dataarrays in the forest presence dataset\n",
    "\n",
    "for variable in forest_presence_ds.data_vars:\n",
    "    year = variable[-4:]\n",
    "    forest_presence_ds = forest_presence_ds.rename({variable: f'forest_presence_{year}'})\n",
    "# forest_presence_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Gets the max value in multiple stacked data arrays within a dataset (last forest year)\n",
    "\n",
    "# https://stackoverflow.com/questions/65149355/is-there-a-faster-way-to-sum-xarray-dataset-variables\n",
    "vars = list(forest_presence_ds.keys())\n",
    "\n",
    "final_forest_year = forest_presence_ds[vars].to_array().max(\"variable\").compute()\n",
    "# final_forest_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_forest_year.rio.set_crs(\"EPSG:4326\")\n",
    "final_forest_year.rio.to_raster(f'{local_out_dir}final_forest_year__{timestr}_{tile_size}_deg.tif', compress='DEFLATE', dtype='uint16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Annual forest state classification</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts all the dataarrays into a dataset\n",
    "\n",
    "forest_data = xr.Dataset({\n",
    "    \"forest_height_previous\": forest_height_previous, \n",
    "    \"forest_height_current\": forest_height_current,\n",
    "    \"forest_loss_detection\": forest_loss_detection\n",
    "    # \"driver\": driver,\n",
    "    # \"planted_forest\": planted_forest,\n",
    "    # \"peat\": peat,\n",
    "    # \"LC_previous\": LC_previous,\n",
    "    # \"LC_next\": LC_next,\n",
    "    # \"burned_area_recent\": burned_area_recent,\n",
    "    # \"final_forest_year\": final_forest_year,\n",
    "    # \"agb_2000\": agb_2000\n",
    "})\n",
    "\n",
    "# forest_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_where(forest_state_array, data):   #data=tuple(where clause, resulting digit)\n",
    "\n",
    "    return xr.where(data.predicate, data.val, forest_state_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies forest state rules to the forest_array_zeros array of 0s\n",
    "def build_decision_tree(forest_data):\n",
    "\n",
    "    print(\"Building classification tree: \", time.strftime(\"%Y%m%d-%H-%M-%S\"))\n",
    "    classifier = CarbonBudgetClassifier(\n",
    "        forest_maintained=Leaf(0.1),           #1\n",
    "        forest_gain=Leaf(0.1),                 #2\n",
    "        forest_loss=Leaf(0.9)\n",
    "        # forest_loss=PlantedForestNode(\n",
    "        #   non_planted=RecentFireNode(\n",
    "        #       no_recent_fire=PeatNode(\n",
    "        #           no_peat=Leaf(0.5),           #3111\n",
    "        #           peat=Leaf(0.55)),            #3112\n",
    "        #       recent_fire=PeatNode(\n",
    "        #           no_peat=Leaf(0.6),           #3121\n",
    "        #           peat=Leaf(0.65)              #3122\n",
    "        #       )\n",
    "        #   ),\n",
    "        #   planted=RecentFireNode(\n",
    "        #       no_recent_fire=PeatNode(\n",
    "        #           no_peat=Leaf(0.7),           #3211\n",
    "        #           peat=Leaf(0.75)),            #3212\n",
    "        #       recent_fire=PeatNode(\n",
    "        #           no_peat=Leaf(0.8),           #3221\n",
    "        #           peat=Leaf(0.85)              #3222\n",
    "        #       )\n",
    "        #   )\n",
    "        # )\n",
    "    )\n",
    "\n",
    "    print(\"Creating classifier: \", time.strftime(\"%Y%m%d-%H-%M-%S\"))\n",
    "    decision_tree = classifier.classify(forest_data)\n",
    "    return decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Builds the decision tree object\n",
    "decision_tree = build_decision_tree(forest_data)    # This only needs to occur once\n",
    "# print(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduces the iterative logic statements of the decsion tree into single statements\n",
    "def reduce_decision_tree(decision_tree, forest_array_zeros):\n",
    "\n",
    "    print(\"Reducing decision tree: \", time.strftime(\"%Y%m%d-%H-%M-%S\"))\n",
    "    forest_state_array = reduce(apply_where, decision_tree, forest_array_zeros)\n",
    "    \n",
    "    print(\"At return statement: \", time.strftime(\"%Y%m%d-%H-%M-%S\"))\n",
    "    return forest_state_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduces the iterative logic statements of the decsion tree into single statements\n",
    "def reduce_decision_tree_map(decision_tree, forest_array_zeros):\n",
    "\n",
    "    print(\"Reducing decision tree: \", time.strftime(\"%Y%m%d-%H-%M-%S\"))\n",
    "    forest_state_array = reduce(apply_where, decision_tree, forest_array_zeros)\n",
    "\n",
    "    # file_name = \"test_states\"\n",
    "    # print(file_name)\n",
    "    # forest_state_array.rio.to_raster(f\"/tmp/test_states.tif\", compress='DEFLATE', dtype='uint8')\n",
    "\n",
    "    # s3_client = boto3.client(\"s3\")\n",
    "    # s3_client.upload_file(f\"/tmp/{file_name}.tif\", \"gfw2-data\", Key=f\"climate/forest_states/{file_name}.tif\")\n",
    "    \n",
    "    print(\"At return statement: \", time.strftime(\"%Y%m%d-%H-%M-%S\"))\n",
    "    return forest_state_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# xarray dataarray of 0s that has the properties of forest_height_current. Used to apply forest states to. \n",
    "forest_array_zeros = xr.zeros_like(forest_height_current)\n",
    "\n",
    "print(\"Assigning forest states and factors: \", time.strftime(\"%Y%m%d-%H-%M-%S\"))\n",
    "# One compute() command for the entire function\n",
    "# per https://docs.dask.org/en/stable/best-practices.html#avoid-calling-compute-repeatedly\n",
    "forest_states_array = dask.compute(reduce_decision_tree(decision_tree, forest_array_zeros))    # Returns a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uris = [forest_height_previous_uri, forest_height_current_uri, forest_loss_detection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio.windows\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "def get_tile_dataset_rio(uri, bounds, transform):\n",
    "    # If the input tile_size is too large, it reverts to 10 (standard tile size)\n",
    "    try:\n",
    "        with rasterio.open(uri) as ds:\n",
    "            return ds.read(1, window=rasterio.windows.from_bounds(*bounds, transform))\n",
    "    except rasterio.errors.RasterioIOError as e:\n",
    "        return np.zeros((chunk_length, chunk_length))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import concurrent.futures\n",
    "import boto3\n",
    "\n",
    "\"\"\"\n",
    "Some code that applies the decision tree to decision_tree_ds to make an xarray of forest_states for the previous and current years\n",
    "\"\"\"\n",
    "\n",
    "# TODO don't map blocks?\n",
    "def map_chunks(block):\n",
    "    futures = []\n",
    "    layers = []\n",
    "\n",
    "    # submit requests to S3 for layers\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        for uri in uris:\n",
    "            futures.append(\n",
    "                executor.submit(get_tile_dataset_rio, uri, block.rio.bounds(), block.rio.transform())\n",
    "            )\n",
    "\n",
    "    # wait for requests to come back with data from S3\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        layers.append(future.result())\n",
    "\n",
    "\n",
    "                       \n",
    "    block = reduce(apply_where, decision_tree, forest_array_zeros)\n",
    "\n",
    "    print(\"Hello\")\n",
    "    \n",
    "    file_name = \"_\".join([str(round(x)) for x in block.rio.bounds()])\n",
    "    print(file_name)\n",
    "    block.rio.to_raster(f\"/tmp/{file_name}.tif\", compress='DEFLATE', dtype='uint8')\n",
    "\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    s3_client.upload_file(f\"/tmp/{file_name}.tif\", \"gfw2-data\", Key=f\"climate/forest_states/{file_name}.tif\")\n",
    "\n",
    "    return block\n",
    "\n",
    "# for tile in tiles:\n",
    "#     blocks = get_blocks_from_tile(tile)\n",
    "#     results = dask.compute(map_blocks, blocks)\n",
    "#     # \"success\", \"success\", \"failure\"\n",
    "\n",
    "forest_states_array = forest_height_previous.map_blocks(map_chunks, template=forest_height_previous).persist() \n",
    "# forest_states_array"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "forest_height_previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_da = xr.DataArray(forest_states_array[0], dims=('y', 'x'), coords={'x': forest_array_zeros['x'], 'y': forest_array_zeros['y']})\n",
    "# states_da.mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"test_states\"\n",
    "print(file_name)\n",
    "print(type(forest_states_array[0]))\n",
    "forest_states_array[0].rio.to_raster(f'{local_out_dir}forest_states_{current_year}__{timestr}_{tile_size}_deg.tif', compress='DEFLATE', dtype='uint32')\n",
    "\n",
    "# s3_client = boto3.client(\"s3\")\n",
    "# s3_client.upload_file(f\"/tmp/{file_name}.tif\", \"gfw2-data\", Key=f\"climate/forest_states/{file_name}.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "factor_array = forest_states_array[0].copy()   # Duplicates forest_state_array so that emission factors can be mapped onto it   \n",
    "\n",
    "# Define the conditions and corresponding emission factors\n",
    "conditions = [factor_array == item.val for item in decision_tree]\n",
    "emission_factors = [item.emission_factor for item in decision_tree]\n",
    "\n",
    "# Initialize an empty result array\n",
    "result_array = factor_array.copy()\n",
    "\n",
    "# Update the result array based on conditions and emission factors\n",
    "for condition, factor in zip(conditions, emission_factors):\n",
    "    result_array = np.where(condition, factor, result_array)\n",
    "\n",
    "# Now, result_array contains the updated values based on your conditions and emission factors\n",
    "factor_array = result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Makes array of forest emission factors based on forest states\n",
    "\n",
    "factor_array = forest_states_array[0].copy()   # Duplicates forest_state_array so that emission factors can be mapped onto it   \n",
    "\n",
    "# Applies factors based on forest states. Courtesy of ChatGPT.\n",
    "print(\"Mapping factor array: \", time.strftime(\"%Y%m%d-%H-%M-%S\"))\n",
    "for item in decision_tree:\n",
    "    factor_array[factor_array == item.val] = item.emission_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Converts the forest states numpy array to a xarray dataarray\n",
    "states_da = xr.DataArray(forest_states_array, dims=('y', 'x'), coords={'x': forest_array_zeros['x'], 'y': forest_array_zeros['y']})\n",
    "\n",
    "# # Converts the forest factors numpy array to a xarray dataarray\n",
    "# factors_da = xr.DataArray(factor_array, dims=('y', 'x'), coords={'x': forest_array_zeros['x'], 'y': forest_array_zeros['y']}).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "flux_current_year_da = dask.array.multiply(agb_2000.values, factors_da).compute()\n",
    "# flux_current_year_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Exports forest state dataarray to raster\n",
    "states_da.rio.set_crs(\"EPSG:4326\")\n",
    "states_da.rio.to_raster(f'{local_out_dir}forest_states_{current_year}__{timestr}_{tile_size}_deg.tif', compress='DEFLATE', dtype='uint32')\n",
    "\n",
    "# # Exports forest factor dataarray to raster\n",
    "# factors_da.rio.set_crs(\"EPSG:4326\")\n",
    "# factors_da.rio.to_raster(f'{local_out_dir}forest_factors_{current_year}__{timestr}_{tile_size}_deg.tif', compress='DEFLATE', dtype='float32')\n",
    "\n",
    "# # Exports current year flux dataarray to raster\n",
    "# flux_current_year_da.rio.set_crs(\"EPSG:4326\")\n",
    "# flux_current_year_da.rio.to_raster(f'{local_out_dir}flux_Mg_CO2_{current_year}__{timestr}_{tile_size}_deg.tif', compress='DEFLATE', dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification definitions\n",
    "\n",
    "maintained = (forest_height_previous >= height_cutoff) & (forest_height_current >= height_cutoff)\n",
    "gained = (forest_height_previous < height_cutoff) & (forest_height_current >= height_cutoff)\n",
    "lost = (((forest_height_previous >= height_cutoff) & (forest_height_current < height_cutoff)) | (forest_loss_detection == 1))\n",
    "no_forest = (forest_height_previous < height_cutoff) & (forest_height_current < height_cutoff)\n",
    "\n",
    "grassland_next = (((LC_next >= 2) & (LC_next <= 26)) | ((LC_next >= 102) & (LC_next <= 126)))\n",
    "\n",
    "forest_next = (((LC_next >= 27) & (LC_next <= 48)) | ((LC_next >= 127) & (LC_next <= 148)))\n",
    "\n",
    "other_next = ((grassland_next == 0) & (forest_next == 0))\n",
    "\n",
    "cropland_previous = (LC_previous == 244)\n",
    "cropland_next = (LC_next == 244)\n",
    "\n",
    "builtup_previous = (LC_previous == 250)\n",
    "builtup_next = (LC_next == 250)\n",
    "\n",
    "grassland_forest_previous = (((LC_previous >= 2) & (LC_previous <= 48)) | ((LC_previous >= 102) & (LC_previous <= 148)))\n",
    "grassland_forest_next = (((LC_next >= 2) & (LC_next <= 48)) | ((LC_next >= 102) & (LC_next <= 148)))  \n",
    "\n",
    "forestry = (driver == 3)\n",
    "\n",
    "non_sdpt_forestry = (forestry & (grassland_forest_previous | grassland_forest_next) & (cropland_previous == 0) & (cropland_next == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summing values in multiple stacked data arrays within a dataset\n",
    "\n",
    "# https://stackoverflow.com/questions/65149355/is-there-a-faster-way-to-sum-xarray-dataset-variables\n",
    "vars_to_sum = [\"forest_height_2016\", \"forest_height_2017\", \"forest_height_2018\", \"forest_height_2019\", \"forest_height_2020\", \"forest_height_2021\"]\n",
    "\n",
    "summed_variables = forest_height_ds[vars_to_sum].to_array().sum(\"variable\").compute()\n",
    "summed_variables\n",
    "# summed_dataset = forest_height_ds.compute()\n",
    "# summed_dataset\n",
    "\n",
    "summed_variables.rio.to_raster(f'{local_out_dir}summed_heights_{current_year}__{timestr}_{tile_size}_deg.tif', compress='DEFLATE', dtype='uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(\"Maintained branch\")\n",
    "    forest_state_array = dask.array.where(\n",
    "        maintained, 1, forest_state_zeros)     #maintained\n",
    "\n",
    "    print(\"Gain branch\")\n",
    "    forest_state_array = dask.array.where(gained, \n",
    "        2, forest_state_array)    #gained\n",
    "\n",
    "    print(\"Loss branch\")\n",
    "\n",
    "    ###Land use change (haven't built out peat and fire branches yet)\n",
    "    #Loss:no SDPT:no non-SDPT forestry:no later forest:cropland next\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year < int(year)) & (forest_next == 0))\n",
    "        & cropland_next, 31111, forest_state_array)\n",
    "    #Loss:no SDPT:no non-SDPT forestry:no later forest:settlement next\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year < int(year)) & (forest_next == 0))\n",
    "        & builtup_next, 31112, forest_state_array)\n",
    "    #Loss:no SDPT:no non-SDPT forestry:no later forest:grassland next\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year < int(year)) & (forest_next == 0))\n",
    "        & grassland_next, 31113, forest_state_array)\n",
    "    #Loss:no SDPT:no non-SDPT forestry:no later forest: other land cover next\n",
    "    forest_state_array = dask.array.where(\n",
    "        lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year < int(year)) & (forest_next == 0))\n",
    "        & ((cropland_next == 0) & (builtup_next == 0) & (grassland_next == 0)), 31114, forest_state_array)\n",
    "\n",
    "    # ### Land cover change\n",
    "    # #Loss:no SDPT:no non-SDPT forestry:later forest:forest next:no recent fire:no peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next) \n",
    "    #     & forest_next & (burned_area_recent == 0) & (peat == 0), 3112111, forest_state_array)\n",
    "    # #Loss:no SDPT:no non-SDPT forestry:later forest:forest next:no recent fire:peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next)\n",
    "    #     & forest_next & (burned_area_recent == 0) & (peat == 1), 3112112, forest_state_array)\n",
    "    # #Loss:no SDPT:no non-SDPT forestry:later forest:forest next:recent fire:no peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next)\n",
    "    #     & forest_next & (burned_area_recent == 1) & (peat == 0), 3112121, forest_state_array)\n",
    "    # #Loss:no SDPT:no non-SDPT forestry:later forest:forest next:recent fire:peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next)\n",
    "    #     & forest_next & (burned_area_recent == 1) & (peat == 1), 3112122, forest_state_array)\n",
    "\n",
    "    # #Loss:no SDPT:no non-SDPT forestry:later forest:grassland next:no recent fire:no peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next)\n",
    "    #     & grassland_next & (burned_area_recent == 0) & (peat == 0), 3112211, forest_state_array)   \n",
    "    # #Loss:no SDPT:no non-SDPT forestry:later forest:grassland next:no recent fire:peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next)\n",
    "    #     & grassland_next & (burned_area_recent == 0) & (peat == 1), 3112212, forest_state_array)\n",
    "    # #Loss:no SDPT:no non-SDPT forestry:later forest:grassland next:recent fire:no peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next)\n",
    "    #     & grassland_next & (burned_area_recent == 1) & (peat == 0), 3112221, forest_state_array)   \n",
    "    # #Loss:no SDPT:no non-SDPT forestry:later forest:grassland next:recent fire:peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next) \n",
    "    #     & grassland_next & (burned_area_recent == 1) & (peat == 1), 3112222, forest_state_array)   \n",
    "    \n",
    "    \n",
    "    # #Loss:no SDPT:no non-SDPT forestry:later forest:other LC next:no recent fire:no peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next)\n",
    "    #     & other_next & (burned_area_recent == 0) & (peat == 0), 3112311, forest_state_array)\n",
    "    # #Loss:no SDPT:no non-SDPT forestry:later forest:other LC next:no recent fire:peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next) \n",
    "    #     & other_next & (burned_area_recent == 0) & (peat == 1), 3112312, forest_state_array)   \n",
    "    # #Loss:no SDPT:no non-SDPT forestry:later forest:other LC next:recent fire:no peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next)\n",
    "    #     & other_next & (burned_area_recent == 1) & (peat == 0), 3112321, forest_state_array)   \n",
    "    # #Loss:no SDPT:no non-SDPT forestry:later forest:other LC next:no recent fire:no peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest == 0) & (non_sdpt_forestry == 0) & ((final_forest_year >= int(year)) | forest_next)\n",
    "    #     & other_next & (burned_area_recent == 1) & (peat == 1), 3112322, forest_state_array)   \n",
    "\n",
    "    # ### Forestry\n",
    "    # # Loss:no SDPT:non-SDPT forestry:no recent fire:no peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest == 0) & non_sdpt_forestry & (burned_area_recent == 0) & (peat == 0), 31211, forest_state_array)   \n",
    "    # #Loss:no SDPT:non-SDPT forestry:no recent fire:peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest == 0) & non_sdpt_forestry & (burned_area_recent == 0) & (peat == 1), 31212, forest_state_array)   \n",
    "    # #Loss:no SDPT:non-SDPT forestry:recent fire:no peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest == 0) & non_sdpt_forestry & (burned_area_recent == 1) & (peat == 0), 31221, forest_state_array)   \n",
    "    # #Loss:no SDPT:non-SDPT forestry:recent fire:peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest == 0) & non_sdpt_forestry & (burned_area_recent == 1) & (peat == 1), 31222, forest_state_array)   \n",
    "    \n",
    "    # ### Forestry\n",
    "    # #Loss:SDPT:no recent fire:no peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest > 0) & (burned_area_recent == 0) & (peat == 0), 3211, forest_state_array)   \n",
    "    # #Loss:SDPT:no recent fire:peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest > 0) & (burned_area_recent == 0) & (peat == 1), 3212, forest_state_array)   \n",
    "    # #Loss:SDPT:recent fire:no peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest > 0) & (burned_area_recent == 1) & (peat == 0), 3221, forest_state_array)  \n",
    "    # #Loss:SDPT:recent fire:peat\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     lost & (planted_forest > 0) & (burned_area_recent == 1) & (peat == 1), 3222, forest_state_array)  \n",
    "\n",
    "    # print(\"No forest\")\n",
    "    # forest_state_array = dask.array.where(\n",
    "    #     no_forest, 4, forest_state_array)     #non-forest remaining non-forest "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
